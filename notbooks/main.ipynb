{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1af539",
   "metadata": {},
   "source": [
    "# Team7 Assiginment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd44cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch에서 인식하는 총 GPU 개수: **1**개\n",
      "   - GPU 0: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import torch\n",
    "def check_gpus_pytorch():\n",
    "    # PyTorch가 CUDA를 지원하는지 확인\n",
    "    if torch.cuda.is_available():\n",
    "        # 사용 가능한 GPU 개수 확인\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"✅ PyTorch에서 인식하는 총 GPU 개수: **{gpu_count}**개\")\n",
    "\n",
    "        # 각 GPU의 이름 확인\n",
    "        for i in range(gpu_count):\n",
    "            print(f\"   - GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        print(\"❌ PyTorch가 CUDA(GPU)를 지원하지 않습니다.\")\n",
    "check_gpus_pytorch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e388819",
   "metadata": {},
   "source": [
    "### Setting and Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0493df46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: . (57477, 9) (3, 4)\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "import torch\n",
    "\n",
    "LOCAL, KAGGLE = \".\", \"/kaggle/input/llm-classification-finetuning\"\n",
    "DATA = LOCAL if os.path.exists(\"./train.csv\") else KAGGLE\n",
    "train = pd.read_csv(f\"{DATA}/train.csv\")\n",
    "test  = pd.read_csv(f\"{DATA}/test.csv\")\n",
    "sample = pd.read_csv(f\"{DATA}/sample_submission.csv\")\n",
    "\n",
    "need = {\"prompt\",\"response_a\",\"response_b\",\"winner_model_a\",\"winner_model_b\",\"winner_tie\"}\n",
    "assert need.issubset(set(train.columns)), f\"column: {need - set(train.columns)} is missing in train.csv\"\n",
    "print(\"DATA:\", DATA, train.shape, test.shape)\n",
    "\n",
    "# target (y)\n",
    "# 0: model_a win, 1: model_b win, 2: tie\n",
    "y = train[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values.argmax(1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "random_state = 20010815\n",
    "val_size = 0.2\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ce45ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/jun_cls/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functions loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Global Functions ###\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def load_model(candidates, idx=0, device=\"cpu\"):\n",
    "    # Load\n",
    "    last_err = None\n",
    "    path = candidates[idx]\n",
    "    try:\n",
    "        print(\"try:\", path)\n",
    "        model = SentenceTransformer(path, device=device)\n",
    "        print(\"loaded model from:\", path)\n",
    "        return model, path\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "    raise RuntimeError(\"Failed to load model. In Kaggle, you need to upload the model folder to Datasets and then link it via 'Add data'. Last error: \" + str(last_err))\n",
    "\n",
    "\n",
    "def build_feat(P, A, B):\n",
    "    AB_diff = A - B\n",
    "    AB_adiff = np.abs(AB_diff)\n",
    "    AB_mul = A * B\n",
    "    PA_mul = P * A\n",
    "    PB_mul = P * B\n",
    "    return np.hstack([P, A, B, AB_diff, AB_adiff, AB_mul, PA_mul, PB_mul])\n",
    "\n",
    "\n",
    "def l2norm(a, eps=1e-12):\n",
    "    n = np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    n = np.clip(n, eps, None)\n",
    "    return a / n\n",
    "\n",
    "def encode_texts(model, texts, batch_size=256):\n",
    "    vecs = []\n",
    "    total_texts = len(texts)\n",
    "    total_batches = (total_texts + batch_size - 1) // batch_size\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        start_time = time.time()\n",
    "        batch = texts[i:i+batch_size].tolist() if isinstance(texts, pd.Series) else texts[i:i+batch_size]\n",
    "        v = model.encode(batch, batch_size=len(batch), convert_to_numpy=True, normalize_embeddings=False, show_progress_bar=False)\n",
    "        vecs.append(v)\n",
    "\n",
    "        batch_num = (i // batch_size) + 1\n",
    "        print(f\"{batch_num}/{total_batches} | time: {time.time() - start_time:.2f}s\", end='\\r', flush=True)\n",
    "    V = np.vstack(vecs)\n",
    "    return l2norm(V)\n",
    "\n",
    "\n",
    "def create_and_save_submission(predictions, filename, test_df, sample_df):\n",
    "    \"\"\"\n",
    "    Creates a Kaggle submission file from model predictions.\n",
    "    Then, it normalizes the probabilities, performs validation checks, and saves the file.\n",
    "    Args:\n",
    "        predictions (np.array): return value of predict_proba() (N, 3)\n",
    "        filename (str): csv filename to save the submission.\n",
    "        test_df (pd.DataFrame): dataframe containing 'id' column.\n",
    "        sample_df (pd.DataFrame): dataframe to align columns with sample submission.\n",
    "    \"\"\"\n",
    "    print(f\"Creating submission file: {filename}...\")\n",
    "    \n",
    "    # 1. Save Submission File\n",
    "    sub_df = pd.DataFrame({\n",
    "        \"id\": test_df[\"id\"],\n",
    "        \"winner_model_a\": predictions[:, 0],\n",
    "        \"winner_model_b\": predictions[:, 1],\n",
    "        \"winner_tie\":     predictions[:, 2],\n",
    "    })\n",
    "\n",
    "    # 2. Normalization check (safety)\n",
    "    probs = sub_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n",
    "    row_sums = probs.sum(axis=1, keepdims=True)\n",
    "    probs = probs / np.clip(row_sums, 1e-15, None)\n",
    "    sub_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]] = probs\n",
    "\n",
    "    # 3. Align columns with sample submission\n",
    "    try:\n",
    "        sub_df = sub_df[sample_df.columns]\n",
    "    except KeyError as e:\n",
    "        print(f\"Warning: Columns in sample_df not found. Saving with default columns. Error: {e}\")\n",
    "\n",
    "    # 4. Save\n",
    "    sub_df.to_csv(filename, index=False)\n",
    "\n",
    "    # 5. Assertions to check file integrity\n",
    "    try:\n",
    "        chk = pd.read_csv(filename)\n",
    "        \n",
    "        assert list(chk.columns) == list(sample_df.columns), \\\n",
    "            f\"Column mismatch. Expected: {list(sample_df.columns)}, Got: {list(chk.columns)}\"\n",
    "        \n",
    "        assert not chk.isna().any().any(), \"NaN values found in submission file.\"\n",
    "        \n",
    "        prob_cols = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
    "        assert np.allclose(chk[prob_cols].sum(1).values, 1.0), \\\n",
    "            \"Probabilities do not sum to 1.0 for all rows.\"\n",
    "            \n",
    "        print(f\"Successfully saved and verified: {filename} (Shape: {sub_df.shape})\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found after saving: {filename}\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"Error: Submission file verification failed! {e}\")\n",
    "    \n",
    "    return sub_df\n",
    "\n",
    "print(\"All functions loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fd96c",
   "metadata": {},
   "source": [
    "### Step0. Equal Distribution\n",
    "All possibility are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89baeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.333333        0.333333    0.333333\n",
       "1   211333        0.333333        0.333333    0.333333\n",
       "2  1233961        0.333333        0.333333    0.333333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"winner_model_a\": np.full(len(test), 1/3),\n",
    "    \"winner_model_b\": np.full(len(test), 1/3),\n",
    "    \"winner_tie\":     np.full(len(test), 1/3),\n",
    "})\n",
    "# sample column order alignment\n",
    "if set(sample.columns) == set(sub.columns):\n",
    "    sub = sub[sample.columns]\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f991a16",
   "metadata": {},
   "source": [
    "## Step 1. Baseline Model\n",
    "a simple baseline using lexical/length features and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building SIMPLE features for Step 1...\n",
      "X_train (simple) shape: (57477, 10), X_test (simple) shape: (3, 10)\n",
      "\n",
      "--- Validating Simple Baseline (Step 1) ---\n",
      "Validation LogLoss: 1.070572\n",
      "\n",
      "Feature Coefficients (Class 0: winner_model_a):\n",
      "p_len_char      -0.0140\n",
      "a_len_char       0.0631\n",
      "a_len_tok        0.0225\n",
      "a_num_sent       0.0298\n",
      "b_len_char      -0.0132\n",
      "b_len_tok       -0.0271\n",
      "b_num_sent      -0.0343\n",
      "d_len_char       0.1060\n",
      "d_len_tok        0.0688\n",
      "d_num_sent       0.0797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/jun_cls/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import os\n",
    "\n",
    "def simple_stats(s):\n",
    "    \"\"\"Calculates basic statistics for the simple baseline.\"\"\"\n",
    "    if not isinstance(s, str): s = \"\"\n",
    "    toks = s.split()\n",
    "    return {\n",
    "        \"len_char\": len(s),\n",
    "        \"len_tok\": len(toks),\n",
    "        \"num_sent\": sum(s.count(x) for x in [\".\", \"!\", \"?\"]), # Incomplete sentence count\n",
    "    }\n",
    "\n",
    "def build_simple_features(df):\n",
    "    \"\"\"Builds minimal features for the Step 1 Simple Baseline.\"\"\"\n",
    "    rows = []\n",
    "    # Use 'response_a' for train, 'response_A' for test if columns differ\n",
    "    if \"response_a\" in df.columns:\n",
    "        cols = [\"prompt\", \"response_a\", \"response_b\"]\n",
    "    else:\n",
    "        cols = [\"prompt\", \"response_A\", \"response_B\"]\n",
    "        \n",
    "    for p, a, b in zip(df[cols[0]], df[cols[1]], df[cols[2]]):\n",
    "        ps = simple_stats(p)\n",
    "        as_ = simple_stats(a)\n",
    "        bs = simple_stats(b)\n",
    "        \n",
    "        rows.append({\n",
    "            # Prompt features\n",
    "            \"p_len_char\": ps[\"len_char\"],\n",
    "            \n",
    "            # Response A features\n",
    "            \"a_len_char\": as_[\"len_char\"],\n",
    "            \"a_len_tok\": as_[\"len_tok\"],\n",
    "            \"a_num_sent\": as_[\"num_sent\"],\n",
    "            \n",
    "            # Response B features\n",
    "            \"b_len_char\": bs[\"len_char\"],\n",
    "            \"b_len_tok\": bs[\"len_tok\"],\n",
    "            \"b_num_sent\": bs[\"num_sent\"],\n",
    "            \n",
    "            # Difference features (A-B)\n",
    "            \"d_len_char\": as_[\"len_char\"] - bs[\"len_char\"],\n",
    "            \"d_len_tok\": as_[\"len_tok\"] - bs[\"len_tok\"],\n",
    "            \"d_num_sent\": as_[\"num_sent\"] - bs[\"num_sent\"],\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "print(\"Building SIMPLE features for Step 1...\")\n",
    "X_train_simple = build_simple_features(train)\n",
    "X_test_simple = build_simple_features(test)\n",
    "print(f\"X_train (simple) shape: {X_train_simple.shape}, X_test (simple) shape: {X_test_simple.shape}\")\n",
    "\n",
    "# Handle NaN/inf as 0\n",
    "X_train_simple = X_train_simple.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "X_test_simple = X_test_simple.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(\"\\n--- Validating Simple Baseline (Step 1) ---\")\n",
    "\n",
    "# Data split for validation\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_train_simple, y, test_size=val_size, random_state=random_state, stratify=y)\n",
    "\n",
    "# Scaling for validation\n",
    "scaler = StandardScaler()\n",
    "X_tr_sc = scaler.fit_transform(X_tr)\n",
    "X_va_sc = scaler.transform(X_va)\n",
    "\n",
    "# Model Training and Evaluation\n",
    "clf = LogisticRegression(max_iter=2000, multi_class=\"multinomial\")\n",
    "clf.fit(X_tr_sc, y_tr)\n",
    "va_pred = clf.predict_proba(X_va_sc)\n",
    "\n",
    "print(f\"Validation LogLoss: {log_loss(y_va, va_pred):.6f}\")\n",
    "\n",
    "# (Optional) Check Feature Importance\n",
    "print(\"\\nFeature Coefficients (Class 0: winner_model_a):\")\n",
    "for name, coef in zip(X_train_simple.columns, clf.coef_[0]):\n",
    "    print(f\"{name:15s} {coef: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1aac0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Full Model for Step 1 Submission ---\n",
      "Full model trained.\n",
      "Prediction on test set complete.\n",
      "Creating submission file: submission_step1_simple_baseline.csv...\n",
      "Successfully saved and verified: submission_step1_simple_baseline.csv (Shape: (3, 4))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/jun_cls/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.325984</td>\n",
       "      <td>0.339632</td>\n",
       "      <td>0.334384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.430757</td>\n",
       "      <td>0.251934</td>\n",
       "      <td>0.317309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.365975</td>\n",
       "      <td>0.331413</td>\n",
       "      <td>0.302613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.325984        0.339632    0.334384\n",
       "1   211333        0.430757        0.251934    0.317309\n",
       "2  1233961        0.365975        0.331413    0.302613"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Training Full Model for Step 1 Submission ---\")\n",
    "\n",
    "# Create a new scaler and fit on ALL training data\n",
    "scaler_full = StandardScaler()\n",
    "X_all_sc = scaler_full.fit_transform(X_train_simple) # Use cleaned X_train_simple\n",
    "# Transform the test data using the full scaler\n",
    "X_test_sc = scaler_full.transform(X_test_simple) # Use cleaned X_test_simple\n",
    "\n",
    "# Train a new model on ALL training data (full 'y')\n",
    "clf_full = LogisticRegression(max_iter=2000, multi_class=\"multinomial\")\n",
    "clf_full.fit(X_all_sc, y) \n",
    "\n",
    "print(\"Full model trained.\")\n",
    "\n",
    "# Predict on Test Data\n",
    "pred_step1 = clf_full.predict_proba(X_test_sc)\n",
    "print(\"Prediction on test set complete.\")\n",
    "\n",
    "create_and_save_submission(\n",
    "    predictions=pred_step1, \n",
    "    filename=\"submission_step1_simple_baseline.csv\",\n",
    "    test_df=test,\n",
    "    sample_df=sample\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809f4a1",
   "metadata": {},
   "source": [
    "### Step 2. Embedding-based Model\n",
    "- Use a pre-trained sentence embedding model\n",
    "- Construct prompt+response embeddings and train a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a56282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] all-MiniLM-L6-v2 already exists → ./models/all-MiniLM-L6-v2\n",
      "[skip] all-MiniLM-L12-v2 already exists → ./models/all-MiniLM-L12-v2\n",
      "[skip] e5-small-v2 already exists → ./models/e5-small-v2\n",
      "[skip] e5-base-v2 already exists → ./models/e5-base-v2\n",
      "[skip] e5-large-v2 already exists → ./models/e5-large-v2\n",
      "[skip] sentence-t5-base already exists → ./models/sentence-t5-base\n",
      "[skip] sentence-t5-large already exists → ./models/sentence-t5-large\n",
      "=== Model Download Complete (existing ones skipped) ===\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "MODELS = {\n",
    "    \"all-MiniLM-L6-v2\":  \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"all-MiniLM-L12-v2\": \"sentence-transformers/all-MiniLM-L12-v2\",\n",
    "    \"e5-small-v2\":       \"intfloat/e5-small-v2\",\n",
    "    \"e5-base-v2\":        \"intfloat/e5-base-v2\",\n",
    "    \"e5-large-v2\":       \"intfloat/e5-large-v2\",\n",
    "    \"sentence-t5-base\":  \"sentence-transformers/sentence-t5-base\",\n",
    "    \"sentence-t5-large\": \"sentence-transformers/sentence-t5-large\",\n",
    "}\n",
    "\n",
    "BASE_DIR = \"./models\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "for name, hub_path in MODELS.items():\n",
    "    save_path = os.path.join(BASE_DIR, name)\n",
    "    if os.path.exists(save_path) and os.listdir(save_path):\n",
    "        print(f\"[skip] {name} already exists → {save_path}\")\n",
    "        continue\n",
    "    print(f\"[download] {name} from {hub_path}\")\n",
    "    try:\n",
    "        model = SentenceTransformer(hub_path)\n",
    "        model.save(save_path)\n",
    "        print(f\" -> saved to {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[fail] {name}: {e}\")\n",
    "\n",
    "print(\"=== Model Download Complete (existing ones skipped) ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62b7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Candidates ===\n",
      "- ./models/all-MiniLM-L6-v2\n",
      "- ./models/all-MiniLM-L12-v2\n",
      "- ./models/e5-small-v2\n",
      "- ./models/e5-base-v2\n",
      "- ./models/e5-large-v2\n",
      "- ./models/sentence-t5-base\n",
      "- ./models/sentence-t5-large\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import os, torch, glob\n",
    "\n",
    "EXPECTED = [\n",
    "    \"all-MiniLM-L6-v2\",\n",
    "    \"all-MiniLM-L12-v2\",\n",
    "    \"e5-small-v2\",\n",
    "    \"e5-base-v2\",\n",
    "    \"e5-large-v2\",\n",
    "    \"sentence-t5-base\",\n",
    "    \"sentence-t5-large\",\n",
    "]\n",
    "\n",
    "def list_existing(paths):\n",
    "    return [p for p in paths if os.path.exists(p) and os.listdir(p)]\n",
    "\n",
    "def set_model_candidates():\n",
    "\n",
    "    if DATA == LOCAL:\n",
    "        # 1) Local: ./models/<name>\n",
    "        local_cands = [os.path.join(\"./models\", n) for n in EXPECTED]\n",
    "        candidates = list_existing(local_cands)\n",
    "    else:\n",
    "        # 2) Kaggle: /kaggle/input/<dataset>/[<bundle>/]<name>\n",
    "        candidates = []\n",
    "        if os.path.exists(\"/kaggle/input\"):\n",
    "            # Uploaded individually\n",
    "            direct = [os.path.join(\"/kaggle/input\", n) for n in EXPECTED]\n",
    "            candidates += list_existing(direct)\n",
    "\n",
    "            # Uploaded bundled\n",
    "            bundles = glob.glob(\"/kaggle/input/*\")\n",
    "            for b in bundles:\n",
    "                for n in EXPECTED:\n",
    "                    candidates += list_existing([os.path.join(b, n)])\n",
    "                    candidates += list_existing(glob.glob(os.path.join(b, \"*\", n)))\n",
    "\n",
    "    return candidates\n",
    "\n",
    "model_candidates = set_model_candidates()\n",
    "\n",
    "print(\"=== Model Candidates ===\")\n",
    "for candidate in model_candidates:\n",
    "    print(\"-\", candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399aff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try: ./models/all-MiniLM-L6-v2\n",
      "loaded model from: ./models/all-MiniLM-L6-v2\n",
      "Load Complete. Using model from: ./models/all-MiniLM-L6-v2\n",
      "prompt_emb.shape:  (57477, 384) a_emb.shape:  (57477, 384) b_emb.shape:  (57477, 384)\n",
      "X.shape:  (57477, 3072) X_te.shape:  (3, 3072)\n",
      "Iteration 1, loss = 1.13490196\n",
      "Validation score: 0.426832\n",
      "Iteration 2, loss = 0.82293057\n",
      "Validation score: 0.397478\n",
      "Iteration 3, loss = 0.54224561\n",
      "Validation score: 0.407480\n",
      "Iteration 4, loss = 0.27053691\n",
      "Validation score: 0.398347\n",
      "Iteration 5, loss = 0.12268374\n",
      "Validation score: 0.412916\n",
      "Iteration 6, loss = 0.06144031\n",
      "Validation score: 0.413133\n",
      "Iteration 7, loss = 0.03738650\n",
      "Validation score: 0.420744\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Model:  ./models/all-MiniLM-L6-v2  | time:  187.7004976272583  seconds\n",
      " MLP Valid LogLoss: 1.0716764008014537 \n",
      " Logistic Valid LogLoss: 1.0958757584014502 \n",
      " \n",
      "try: ./models/all-MiniLM-L12-v2\n",
      "loaded model from: ./models/all-MiniLM-L12-v2\n",
      "Load Complete. Using model from: ./models/all-MiniLM-L12-v2\n",
      "prompt_emb.shape:  (57477, 384) a_emb.shape:  (57477, 384) b_emb.shape:  (57477, 384)\n",
      "X.shape:  (57477, 3072) X_te.shape:  (3, 3072)\n",
      "Iteration 1, loss = 1.14844959\n",
      "Validation score: 0.423788\n",
      "Iteration 2, loss = 0.83828016\n",
      "Validation score: 0.422048\n",
      "Iteration 3, loss = 0.56415843\n",
      "Validation score: 0.414655\n",
      "Iteration 4, loss = 0.29212091\n",
      "Validation score: 0.418569\n",
      "Iteration 5, loss = 0.13465585\n",
      "Validation score: 0.406610\n",
      "Iteration 6, loss = 0.07510157\n",
      "Validation score: 0.423570\n",
      "Iteration 7, loss = 0.04576182\n",
      "Validation score: 0.426180\n",
      "Iteration 8, loss = 0.03678972\n",
      "Validation score: 0.428137\n",
      "Iteration 9, loss = 0.03517932\n",
      "Validation score: 0.421831\n",
      "Iteration 10, loss = 0.03216712\n",
      "Validation score: 0.421613\n",
      "Iteration 11, loss = 0.02434022\n",
      "Validation score: 0.423570\n",
      "Iteration 12, loss = 0.02438111\n",
      "Validation score: 0.420744\n",
      "Iteration 13, loss = 0.02099182\n",
      "Validation score: 0.418569\n",
      "Iteration 14, loss = 0.02093289\n",
      "Validation score: 0.425745\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Model:  ./models/all-MiniLM-L12-v2  | time:  176.0339858531952  seconds\n",
      " MLP Valid LogLoss: 2.104881812655 \n",
      " Logistic Valid LogLoss: 1.110176271772776 \n",
      " \n",
      "try: ./models/e5-small-v2\n",
      "loaded model from: ./models/e5-small-v2\n",
      "Load Complete. Using model from: ./models/e5-small-v2\n",
      "prompt_emb.shape:  (57477, 384) a_emb.shape:  (57477, 384) b_emb.shape:  (57477, 384)\n",
      "X.shape:  (57477, 3072) X_te.shape:  (3, 3072)\n",
      "Iteration 1, loss = 1.11879641\n",
      "Validation score: 0.445532\n",
      "Iteration 2, loss = 0.81287694\n",
      "Validation score: 0.440096\n",
      "Iteration 3, loss = 0.55072483\n",
      "Validation score: 0.432703\n",
      "Iteration 4, loss = 0.28090429\n",
      "Validation score: 0.435529\n",
      "Iteration 5, loss = 0.12491101\n",
      "Validation score: 0.435529\n",
      "Iteration 6, loss = 0.05792794\n",
      "Validation score: 0.427702\n",
      "Iteration 7, loss = 0.03228160\n",
      "Validation score: 0.432703\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Model:  ./models/e5-small-v2  | time:  599.2235248088837  seconds\n",
      " MLP Valid LogLoss: 1.0532676601393038 \n",
      " Logistic Valid LogLoss: 1.1000358966177224 \n",
      " \n",
      "try: ./models/e5-base-v2\n",
      "loaded model from: ./models/e5-base-v2\n",
      "Load Complete. Using model from: ./models/e5-base-v2\n",
      "prompt_emb.shape:  (57477, 768) a_emb.shape:  (57477, 768) b_emb.shape:  (57477, 768)\n",
      "X.shape:  (57477, 6144) X_te.shape:  (3, 6144)\n",
      "Iteration 1, loss = 1.13356855\n",
      "Validation score: 0.454229\n",
      "Iteration 2, loss = 0.79974375\n",
      "Validation score: 0.425310\n",
      "Iteration 3, loss = 0.52050830\n",
      "Validation score: 0.436399\n",
      "Iteration 4, loss = 0.24929814\n",
      "Validation score: 0.429876\n",
      "Iteration 5, loss = 0.11346934\n",
      "Validation score: 0.439226\n",
      "Iteration 6, loss = 0.06334354\n",
      "Validation score: 0.427267\n",
      "Iteration 7, loss = 0.04174680\n",
      "Validation score: 0.438791\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Model:  ./models/e5-base-v2  | time:  1499.3062391281128  seconds\n",
      " MLP Valid LogLoss: 1.0577391819930158 \n",
      " Logistic Valid LogLoss: 1.171535905926799 \n",
      " \n",
      "try: ./models/e5-large-v2\n",
      "loaded model from: ./models/e5-large-v2\n",
      "Load Complete. Using model from: ./models/e5-large-v2\n",
      "prompt_emb.shape:  (57477, 1024) a_emb.shape:  (57477, 1024) b_emb.shape:  (57477, 1024)\n",
      "X.shape:  (57477, 8192) X_te.shape:  (3, 8192)\n",
      "Iteration 1, loss = 1.18527048\n",
      "Validation score: 0.445532\n",
      "Iteration 2, loss = 0.76042780\n",
      "Validation score: 0.433355\n",
      "Iteration 3, loss = 0.44194516\n",
      "Validation score: 0.443140\n",
      "Iteration 4, loss = 0.18663940\n",
      "Validation score: 0.446401\n",
      "Iteration 5, loss = 0.08123741\n",
      "Validation score: 0.436617\n",
      "Iteration 6, loss = 0.05090452\n",
      "Validation score: 0.445749\n",
      "Iteration 7, loss = 0.03684762\n",
      "Validation score: 0.446836\n",
      "Iteration 8, loss = 0.02767842\n",
      "Validation score: 0.440748\n",
      "Iteration 9, loss = 0.01887203\n",
      "Validation score: 0.439661\n",
      "Iteration 10, loss = 0.02270562\n",
      "Validation score: 0.440965\n",
      "Iteration 11, loss = 0.02299094\n",
      "Validation score: 0.432920\n",
      "Iteration 12, loss = 0.02498225\n",
      "Validation score: 0.440965\n",
      "Iteration 13, loss = 0.02509089\n",
      "Validation score: 0.438791\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Model:  ./models/e5-large-v2  | time:  5007.105760574341  seconds\n",
      " MLP Valid LogLoss: 2.13590212489048 \n",
      " Logistic Valid LogLoss: 1.2736977955565107 \n",
      " \n",
      "try: ./models/sentence-t5-base\n",
      "loaded model from: ./models/sentence-t5-base\n",
      "Load Complete. Using model from: ./models/sentence-t5-base\n",
      "prompt_emb.shape:  (57477, 768) a_emb.shape:  (57477, 768) b_emb.shape:  (57477, 768)\n",
      "X.shape:  (57477, 6144) X_te.shape:  (3, 6144)\n",
      "Iteration 1, loss = 1.19126989\n",
      "Validation score: 0.424223\n",
      "Iteration 2, loss = 0.88382486\n",
      "Validation score: 0.425745\n",
      "Iteration 3, loss = 0.66785092\n",
      "Validation score: 0.425310\n",
      "Iteration 4, loss = 0.43507718\n",
      "Validation score: 0.420526\n",
      "Iteration 5, loss = 0.25121603\n",
      "Validation score: 0.426832\n",
      "Iteration 6, loss = 0.14702711\n",
      "Validation score: 0.415743\n",
      "Iteration 7, loss = 0.09699133\n",
      "Validation score: 0.423788\n",
      "Iteration 8, loss = 0.07296595\n",
      "Validation score: 0.416177\n",
      "Iteration 9, loss = 0.07423672\n",
      "Validation score: 0.416830\n",
      "Iteration 10, loss = 0.06808588\n",
      "Validation score: 0.416612\n",
      "Iteration 11, loss = 0.05921452\n",
      "Validation score: 0.410959\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Model:  ./models/sentence-t5-base  | time:  2035.7269389629364  seconds\n",
      " MLP Valid LogLoss: 1.7335017181311778 \n",
      " Logistic Valid LogLoss: 1.1751141035605448 \n",
      " \n",
      "try: ./models/sentence-t5-large\n",
      "loaded model from: ./models/sentence-t5-large\n",
      "Load Complete. Using model from: ./models/sentence-t5-large\n",
      "prompt_emb.shape:  (57477, 768) a_emb.shape:  (57477, 768) b_emb.shape:  (57477, 768)\n",
      "X.shape:  (57477, 6144) X_te.shape:  (3, 6144)\n",
      "Iteration 1, loss = 1.16644657\n",
      "Validation score: 0.414220\n",
      "Iteration 2, loss = 0.85116425\n",
      "Validation score: 0.418569\n",
      "Iteration 3, loss = 0.60679989\n",
      "Validation score: 0.424223\n",
      "Iteration 4, loss = 0.36535783\n",
      "Validation score: 0.423788\n",
      "Iteration 5, loss = 0.19883662\n",
      "Validation score: 0.421179\n",
      "Iteration 6, loss = 0.10995619\n",
      "Validation score: 0.425745\n",
      "Iteration 7, loss = 0.07160150\n",
      "Validation score: 0.428789\n",
      "Iteration 8, loss = 0.05531829\n",
      "Validation score: 0.428571\n",
      "Iteration 9, loss = 0.04578791\n",
      "Validation score: 0.426614\n",
      "Iteration 10, loss = 0.04701835\n",
      "Validation score: 0.420091\n",
      "Iteration 11, loss = 0.04349868\n",
      "Validation score: 0.425310\n",
      "Iteration 12, loss = 0.04504261\n",
      "Validation score: 0.416177\n",
      "Iteration 13, loss = 0.07265731\n",
      "Validation score: 0.418352\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Model:  ./models/sentence-t5-large  | time:  2469.4236154556274  seconds\n",
      " MLP Valid LogLoss: 2.113508188906165 \n",
      " Logistic Valid LogLoss: 1.181792716299468 \n",
      " \n",
      "\n",
      "=== Summary of Results ===\n",
      "                        model     time_sec  mlp_val_logloss  \\\n",
      "0   ./models/all-MiniLM-L6-v2   187.700498         1.071676   \n",
      "1  ./models/all-MiniLM-L12-v2   176.033986         2.104882   \n",
      "2        ./models/e5-small-v2   599.223525         1.053268   \n",
      "3         ./models/e5-base-v2  1499.306239         1.057739   \n",
      "4        ./models/e5-large-v2  5007.105761         2.135902   \n",
      "5   ./models/sentence-t5-base  2035.726939         1.733502   \n",
      "6  ./models/sentence-t5-large  2469.423615         2.113508   \n",
      "\n",
      "   logistic_val_logloss  \n",
      "0              1.095876  \n",
      "1              1.110176  \n",
      "2              1.100036  \n",
      "3              1.171536  \n",
      "4              1.273698  \n",
      "5              1.175114  \n",
      "6              1.181793  \n"
     ]
    }
   ],
   "source": [
    "import math, torch, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "model_names = []\n",
    "times = []\n",
    "mlp_val_losses = []\n",
    "logistic_val_losses = []\n",
    "\n",
    "for idx, model in enumerate(model_candidates):\n",
    "    start_time = time.time()\n",
    "    model, model_src = load_model(model_candidates, idx=idx, device=device)\n",
    "    print(\"Load Complete. Using model from:\", model_src)\n",
    "\n",
    "    print(\"Encoding texts...\")\n",
    "    prompt_emb = encode_texts(model, train[\"prompt\"])\n",
    "    print(\"Prompt encoding complete.\")\n",
    "    a_emb = encode_texts(model, train[\"response_a\"])\n",
    "    print(\"Response A encoding complete.\")\n",
    "    b_emb = encode_texts(model, train[\"response_b\"])\n",
    "    print(\"Response B encoding complete.\")\n",
    "\n",
    "    prompt_emb_te = encode_texts(model, test[\"prompt\"])\n",
    "    a_emb_te = encode_texts(model, test[\"response_a\"])\n",
    "    b_emb_te = encode_texts(model, test[\"response_b\"])\n",
    "    print(\"Test set encoding complete.\")\n",
    "\n",
    "    # prompt_emb.shape, a_emb.shape, b_emb.shape\n",
    "    print(\"prompt_emb.shape: \", prompt_emb.shape, \"a_emb.shape: \", a_emb.shape, \"b_emb.shape: \", b_emb.shape)\n",
    "\n",
    "    X = build_feat(prompt_emb, a_emb, b_emb)\n",
    "    X_te = build_feat(prompt_emb_te, a_emb_te, b_emb_te)\n",
    "    print(\"X.shape: \", X.shape, \"X_te.shape: \", X_te.shape)\n",
    "\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=val_size, stratify=y, random_state=random_state)\n",
    "\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_tr_sc = scaler.fit_transform(X_tr)\n",
    "    X_va_sc = scaler.transform(X_va)\n",
    "\n",
    "    ### Logistic Regression ###\n",
    "    clf = LogisticRegression(max_iter=2000, random_state=random_state) \n",
    "    clf.fit(X_tr_sc, y_tr)\n",
    "    va_pred_logistic = clf.predict_proba(X_va_sc)\n",
    "\n",
    "    ### MLP Classifier ###\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(512, 256),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=1e-4,          # L2\n",
    "        batch_size=512,\n",
    "        learning_rate_init=1e-3,\n",
    "        max_iter=100,        \n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=5,\n",
    "        random_state=random_state,\n",
    "        # verbose=False,\n",
    "        verbose=True,\n",
    "    )\n",
    "    mlp.fit(X_tr_sc, y_tr)\n",
    "    va_pred_mlp = mlp.predict_proba(X_va_sc)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "\n",
    "    print(\"\\nModel: \", model_src, \" | time: \", elapsed, \" seconds\\n\", \n",
    "          \"MLP Valid LogLoss:\", log_loss(y_va, va_pred_mlp), \"\\n\", \n",
    "          \"Logistic Valid LogLoss:\", log_loss(y_va, va_pred_logistic), \"\\n\", \"\")\n",
    "    model_names.append(model_src)\n",
    "    times.append(elapsed)\n",
    "    mlp_val_losses.append(log_loss(y_va, va_pred_mlp))\n",
    "    logistic_val_losses.append(log_loss(y_va, va_pred_logistic))\n",
    "\n",
    "import pandas as pd\n",
    "results = pd.DataFrame({\n",
    "    \"model\": model_names,\n",
    "    \"time_sec\": times,\n",
    "    \"mlp_val_logloss\": mlp_val_losses,\n",
    "    \"logistic_val_logloss\": logistic_val_losses,\n",
    "})\n",
    "print(\"\\n=== Summary of Results ===\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a48e117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try: ./models/e5-small-v2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to load model. In Kaggle, you need to upload the model folder to Datasets and then link it via 'Add data'. Last error: name 'SentenceTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Use GPU for encoding\u001b[39;00m\n\u001b[1;32m     14\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m sbert_model, model_src \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mBEST_MODEL_PATH\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Encode ALL texts (Train + Test)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# (Assumes 'encode_texts' and 'build_feat' from cell 5399aff3 are in memory)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding texts for FULL dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(candidates, idx, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     12\u001b[0m     last_err \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load model. In Kaggle, you need to upload the model folder to Datasets and then link it via \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdd data\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Last error: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(last_err))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to load model. In Kaggle, you need to upload the model folder to Datasets and then link it via 'Add data'. Last error: name 'SentenceTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib # Using joblib as in Candidate 3\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "BEST_MODEL_NAME = \"e5-small-v2\"\n",
    "BEST_MODEL_PATH = f\"./models/{BEST_MODEL_NAME}\"\n",
    "\n",
    "# Use GPU for encoding\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sbert_model, model_src = load_model([BEST_MODEL_PATH], idx=0, device=device)\n",
    "\n",
    "# Encode ALL texts (Train + Test)\n",
    "# (Assumes 'encode_texts' and 'build_feat' from cell 5399aff3 are in memory)\n",
    "print(\"Encoding texts for FULL dataset...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Encode FULL training data\n",
    "prompt_emb_full = encode_texts(sbert_model, train[\"prompt\"])\n",
    "a_emb_full = encode_texts(sbert_model, train[\"response_a\"])\n",
    "b_emb_full = encode_texts(sbert_model, train[\"response_b\"])\n",
    "\n",
    "# Build FULL training features\n",
    "# This is the 'X' for our final model\n",
    "X_final_step2 = build_feat(prompt_emb_full, a_emb_full, b_emb_full)\n",
    "\n",
    "# Encode test data\n",
    "prompt_emb_te = encode_texts(sbert_model, test[\"prompt\"])\n",
    "a_emb_te = encode_texts(sbert_model, test[\"response_a\"])\n",
    "b_emb_te = encode_texts(sbert_model, test[\"response_b\"])\n",
    "\n",
    "# Build test features\n",
    "# This is the 'X_te' for our final model\n",
    "X_test_final_step2 = build_feat(prompt_emb_te, a_emb_te, b_emb_te)\n",
    "\n",
    "# Clean up memory\n",
    "del sbert_model, prompt_emb_full, a_emb_full, b_emb_full, prompt_emb_te, a_emb_te, b_emb_te\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "print(f\"Full feature extraction complete. Time: {time.time() - start_time:.2f}s\")\n",
    "print(f\"Full Train Features: {X_final_step2.shape}\")\n",
    "print(f\"Test Features: {X_test_final_step2.shape}\")\n",
    "\n",
    "print(\"Fitting StandardScaler on full training data...\")\n",
    "scaler_final_step2 = StandardScaler()\n",
    "X_all_sc = scaler_final_step2.fit_transform(X_final_step2)\n",
    "X_te_sc = scaler_final_step2.transform(X_test_final_step2)\n",
    "\n",
    "# --- Train MLPClassifier on ALL data ---\n",
    "print(\"Training final MLPClassifier on ALL data...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use parameters from your template\n",
    "mlp_full = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,\n",
    "    batch_size=512,\n",
    "    learning_rate_init=1e-3,\n",
    "    max_iter=100,        \n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=7,  \n",
    "    verbose=False,      \n",
    ")\n",
    "\n",
    "mlp_full.fit(X_all_sc, y)\n",
    "print(f\"Full training complete. Time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "# Predict on Test Data\n",
    "pred = mlp_full.predict_proba(X_te_sc)\n",
    "print(\"Prediction on test set complete.\")\n",
    "\n",
    "create_and_save_submission(\n",
    "    predictions=pred, \n",
    "    filename=f\"submission_step2_{BEST_MODEL_NAME}_mlp.csv\",\n",
    "    test_df=test,\n",
    "    sample_df=sample\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205e656",
   "metadata": {},
   "source": [
    "### Step 3. Model Extensions\n",
    "- Explore bias-aware features (position bias, verbosity).\n",
    "- Try lightweight fine-tuning (e.g., DeBERTa-small + LoRA).\n",
    "- Experiment with calibration or ensembling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35351a43",
   "metadata": {},
   "source": [
    "### Candidate 1: DeBERTa + LoRA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6405d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: microsoft/deberta-v3-base\n",
      "LoRA adapter will be saved to: ./models/lora_adapter_deberta-v3-base\n",
      "Training samples: 45981, Validation samples: 11496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/jun_cls/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 45981/45981 [00:23<00:00, 1936.88 examples/s]\n",
      "Map: 100%|██████████| 11496/11496 [00:07<00:00, 1638.31 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Candidate 1: DeBERTa + LoRA ###\n",
    "import torch\n",
    "import os\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    BitsAndBytesConfig # For QLoRA (4-bit quantization)\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType\n",
    ")\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.special import softmax\n",
    "\n",
    "# MODEL_NAME = \"all-MiniLM-L6-v2\" # Can not use\n",
    "# MODEL_PATH = f\"./models/{MODEL_NAME}\"\n",
    "MODEL_NAME = f\"microsoft/deberta-v3-base\"\n",
    "\n",
    "max_length = 512 # Max length(tokens) for DeBERTa\n",
    "# max_length = 1024 # Max length(tokens) for DeBERTa\n",
    "\n",
    "LORA_ADAPTER_DIR = f\"./models/lora_adapter_{MODEL_NAME.split('/')[-1]}\"\n",
    "\n",
    "print(f\"Using model: {MODEL_NAME}\")\n",
    "print(f\"LoRA adapter will be saved to: {LORA_ADAPTER_DIR}\")\n",
    "\n",
    "train_df_lora = train.copy()\n",
    "train_df_lora['labels'] = y\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df_lora,\n",
    "    test_size=val_size,\n",
    "\n",
    "    stratify=train_df_lora['labels']\n",
    ")\n",
    "print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n",
    "\n",
    "# Convert to Hugging Face 'Dataset' object\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Load the tokenizer for our model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # This formats the input as: [CLS] prompt [SEP] A: response_a [SEP] B: response_b [SEP]\n",
    "    # This is a robust way to present the three pieces of text to the model\n",
    "    \n",
    "    # Combine response_a and response_b into a single string\n",
    "    response_pair = [f\"A: {a} {tokenizer.sep_token} B: {b}\" for a, b in zip(examples['response_a'], examples['response_b'])]\n",
    "    \n",
    "    # Tokenize, using prompt as the first sequence and the combined response as the second\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['prompt'],\n",
    "        response_pair, # This will be the second sequence\n",
    "        max_length=max_length,\n",
    "        truncation=True, # Need to consider whitch option is better\n",
    "        padding=False # DataCollator will handle dynamic padding\n",
    "    )\n",
    "    \n",
    "    # Add labels\n",
    "    tokenized_inputs[\"labels\"] = examples[\"labels\"]\n",
    "    return tokenized_inputs\n",
    "\n",
    "print(\"Tokenizing datasets...\")\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_df.columns.tolist())\n",
    "tokenized_val_dataset = val_dataset.map(preprocess_function, batched=True, remove_columns=val_df.columns.tolist())\n",
    "\n",
    "\n",
    "# Data collator will dynamically pad batches to the max length *in that batch*\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "print(\"Data preparation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a504895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA adapter already exists at: ./models/lora_adapter_deberta-v3-base\n",
      "Skipping training and loading existing adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_1781112/995906066.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded existing LoRA adapter.\n",
      "\n",
      "=== Generating Kaggle Submission ===\n",
      "Tokenizing test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3/3 [00:00<00:00, 280.59 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data tokenization complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submission file: submission_candidate1_deberta_lora_deberta-v3-base.csv...\n",
      "Successfully saved and verified: submission_candidate1_deberta_lora_deberta-v3-base.csv (Shape: (3, 4))\n",
      "Kaggle submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning with LoRA (NO Quantization)\n",
    "# FINAL SOLUTION: Skip quantization entirely - it has compatibility issues with DeBERTa-v3\n",
    "# Use gradient checkpointing for memory efficiency\n",
    "\n",
    "# Check if LoRA adapter already exists\n",
    "if os.path.exists(LORA_ADAPTER_DIR) and os.path.exists(os.path.join(LORA_ADAPTER_DIR, \"adapter_config.json\")):\n",
    "    print(f\"LoRA adapter already exists at: {LORA_ADAPTER_DIR}\")\n",
    "    print(\"Skipping training and loading existing adapter...\")\n",
    "    \n",
    "    # Load base model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=3,\n",
    "    )\n",
    "    \n",
    "    # Load the saved LoRA adapter\n",
    "    from peft import PeftModel\n",
    "    peft_model = PeftModel.from_pretrained(model, LORA_ADAPTER_DIR)\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LORA_ADAPTER_DIR)\n",
    "    \n",
    "    # Create a minimal trainer for prediction only\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./{MODEL_NAME.split('/')[-1]}-checkpoints\",\n",
    "        per_device_eval_batch_size=8,\n",
    "        fp16=False,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=peft_model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    print(\"Successfully loaded existing LoRA adapter.\")\n",
    "    \n",
    "else:\n",
    "    print(\"No existing LoRA adapter found. Starting training from scratch...\")\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=3,\n",
    "    )\n",
    "\n",
    "    # Enable gradient checkpointing to save memory\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        target_modules=[\n",
    "            \"query_proj\", \n",
    "            \"key_proj\", \n",
    "            \"value_proj\",\n",
    "            \"dense\"\n",
    "        ],\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        inference_mode=False\n",
    "    )\n",
    "    # lora_config = LoraConfig(\n",
    "    #     r=16,\n",
    "    #     lora_alpha=32,\n",
    "    #     target_modules=[\n",
    "    #         \"query_layer\",  # <-- FIX: \"query_proj\" -> \"query_layer\"\n",
    "    #         \"key_layer\",    # <-- FIX: \"key_proj\" -> \"key_layer\"\n",
    "    #         \"value_layer\",  # <-- FIX: \"value_proj\" -> \"value_layer\"\n",
    "    #         \"dense\"         # 'dense' is correct and targets FFN layers\n",
    "    #     ],\n",
    "    #     lora_dropout=0.1,\n",
    "    #     bias=\"none\",\n",
    "    #     task_type=TaskType.SEQ_CLS # This is a sequence classification task\n",
    "    # )\n",
    "    # Apply LoRA to the model\n",
    "    peft_model = get_peft_model(model, lora_config)\n",
    "    peft_model.print_trainable_parameters()\n",
    "\n",
    "    # --- Define Custom Compute Metrics ---\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        probs = softmax(logits, axis=1)\n",
    "        \n",
    "        eps = 1e-15\n",
    "        probs = np.clip(probs, eps, 1 - eps)\n",
    "        \n",
    "        loss = log_loss(labels, probs)\n",
    "        return {\"log_loss\": loss}\n",
    "\n",
    "    # --- Define Training Arguments ---\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./{MODEL_NAME.split('/')[-1]}-checkpoints\",\n",
    "        num_train_epochs=2,\n",
    "        per_device_train_batch_size=4,  # Reduced for memory\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=2,  # Effective batch size = 4*2 = 8\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=200,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=200,\n",
    "\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"log_loss\",\n",
    "        greater_is_better=False,\n",
    "\n",
    "        logging_steps=100,\n",
    "        fp16=False,  # Disable fp16 due to gradient checkpointing conflict\n",
    "        report_to=\"none\",\n",
    "        gradient_checkpointing=True,  # Enable gradient checkpointing\n",
    "    )\n",
    "\n",
    "    # --- Initialize Trainer ---\n",
    "    trainer = Trainer(\n",
    "        model=peft_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # --- Start Training ---\n",
    "    print(\"Starting fine-tuning...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # --- Save the final LoRA adapter ---\n",
    "    # This saves only the small, trainable adapter weights\n",
    "    os.makedirs(LORA_ADAPTER_DIR, exist_ok=True)\n",
    "    trainer.model.save_pretrained(LORA_ADAPTER_DIR)\n",
    "\n",
    "    # Also save the tokenizer\n",
    "    tokenizer.save_pretrained(LORA_ADAPTER_DIR)\n",
    "\n",
    "    print(f\"Training complete. LoRA adapter saved to: {LORA_ADAPTER_DIR}\")\n",
    "\n",
    "# --- Predict on Test Data and Create Kaggle Submission ---\n",
    "print(\"\\n=== Generating Kaggle Submission ===\")\n",
    "\n",
    "# Make predictions on the tokenized test dataset\n",
    "def preprocess_test_function(examples):\n",
    "    # This formats the input as: [CLS] prompt [SEP] A: response_a [SEP] B: response_b [SEP]\n",
    "    \n",
    "    # Combine response_a and response_b into a single string\n",
    "    response_pair = [f\"A: {a} {tokenizer.sep_token} B: {b}\" for a, b in zip(examples['response_a'], examples['response_b'])]\n",
    "    \n",
    "    # Tokenize, using prompt as the first sequence and the combined response as the second\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['prompt'],\n",
    "        response_pair, # This will be the second sequence\n",
    "        max_length=max_length,\n",
    "        truncation=True, # Need to consider whitch option is better\n",
    "        padding=False # DataCollator will handle dynamic padding\n",
    "    )\n",
    "    return tokenized_inputs\n",
    "print(\"Tokenizing test dataset...\")\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_test_function, batched=True, remove_columns=test.columns.tolist())\n",
    "\n",
    "print(\"Test data tokenization complete.\")\n",
    "\n",
    "predictions = trainer.predict(tokenized_test_dataset)\n",
    "\n",
    "# Extract logits and convert to probabilities\n",
    "test_logits = predictions.predictions\n",
    "test_probs = softmax(test_logits, axis=1)\n",
    "\n",
    "# Create submission file using the helper function\n",
    "create_and_save_submission(\n",
    "    predictions=test_probs,\n",
    "    filename=f\"submission_candidate1_deberta_lora_{MODEL_NAME.split('/')[-1]}.csv\",\n",
    "    test_df=test,\n",
    "    sample_df=sample\n",
    ")\n",
    "\n",
    "print(\"Kaggle submission file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc0fbb",
   "metadata": {},
   "source": [
    "### Candidate 1: Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0c63740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Candidate 1 (DeBERTa + LoRA): Calibration ===\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation LogLoss BEFORE Calibration: 1.098774\n",
      "Applying Isotonic calibration...\n",
      "Validation LogLoss AFTER Calibration: 1.073453\n",
      "Improvement: 0.025321\n",
      "\n",
      "Generating calibrated predictions for test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submission file: submission_candidate1_deberta_lora_CALIBRATED.csv...\n",
      "Successfully saved and verified: submission_candidate1_deberta_lora_CALIBRATED.csv (Shape: (3, 4))\n",
      "\n",
      "=== Candidate 1 Summary ===\n",
      "Before Calibration - Val LogLoss: 1.098774\n",
      "After Calibration  - Val LogLoss: 1.073453\n",
      "Final submission saved with calibration.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n=== Candidate 1 (DeBERTa + LoRA): Calibration ===\")\n",
    "\n",
    "# Get validation predictions from the existing trainer\n",
    "val_predictions = trainer.predict(tokenized_val_dataset)\n",
    "val_logits = val_predictions.predictions\n",
    "val_probs_before = softmax(val_logits, axis=1)\n",
    "\n",
    "# Get true labels from val_df\n",
    "y_val_c1 = val_df['labels'].values\n",
    "\n",
    "# Calculate log loss BEFORE calibration\n",
    "logloss_before = log_loss(y_val_c1, val_probs_before)\n",
    "print(f\"Validation LogLoss BEFORE Calibration: {logloss_before:.6f}\")\n",
    "\n",
    "# Apply Isotonic Calibration per class\n",
    "# We'll calibrate each class probability separately\n",
    "print(\"Applying Isotonic calibration...\")\n",
    "\n",
    "calibrators = []\n",
    "val_probs_calibrated = np.zeros_like(val_probs_before)\n",
    "\n",
    "for class_idx in range(3):\n",
    "    # Get probabilities for this class\n",
    "    class_probs = val_probs_before[:, class_idx]\n",
    "    \n",
    "    # Create binary labels (1 if true class, 0 otherwise)\n",
    "    y_binary = (y_val_c1 == class_idx).astype(int)\n",
    "    \n",
    "    # Fit isotonic regression\n",
    "    iso = IsotonicRegression(out_of_bounds='clip')\n",
    "    iso.fit(class_probs, y_binary)\n",
    "    \n",
    "    # Calibrate\n",
    "    val_probs_calibrated[:, class_idx] = iso.predict(class_probs)\n",
    "    \n",
    "    calibrators.append(iso)\n",
    "\n",
    "# Normalize probabilities to sum to 1\n",
    "row_sums = val_probs_calibrated.sum(axis=1, keepdims=True)\n",
    "val_probs_calibrated = val_probs_calibrated / np.clip(row_sums, 1e-15, None)\n",
    "\n",
    "# Calculate log loss AFTER calibration\n",
    "logloss_after = log_loss(y_val_c1, val_probs_calibrated)\n",
    "print(f\"Validation LogLoss AFTER Calibration: {logloss_after:.6f}\")\n",
    "print(f\"Improvement: {logloss_before - logloss_after:.6f}\")\n",
    "\n",
    "# Now predict on test set with calibration\n",
    "print(\"\\nGenerating calibrated predictions for test set...\")\n",
    "\n",
    "# Get test predictions\n",
    "test_predictions = trainer.predict(tokenized_test_dataset)\n",
    "test_logits = test_predictions.predictions\n",
    "test_probs_uncalibrated = softmax(test_logits, axis=1)\n",
    "\n",
    "# Apply calibration\n",
    "test_probs_calibrated = np.zeros_like(test_probs_uncalibrated)\n",
    "for class_idx in range(3):\n",
    "    class_probs = test_probs_uncalibrated[:, class_idx]\n",
    "    test_probs_calibrated[:, class_idx] = calibrators[class_idx].predict(class_probs)\n",
    "\n",
    "# Normalize\n",
    "row_sums = test_probs_calibrated.sum(axis=1, keepdims=True)\n",
    "test_probs_calibrated = test_probs_calibrated / np.clip(row_sums, 1e-15, None)\n",
    "\n",
    "# Save calibrated submission\n",
    "create_and_save_submission(\n",
    "    predictions=test_probs_calibrated,\n",
    "    filename=f\"submission_candidate1_deberta_lora_CALIBRATED.csv\",\n",
    "    test_df=test,\n",
    "    sample_df=sample\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Candidate 1 Summary ===\")\n",
    "print(f\"Before Calibration - Val LogLoss: {logloss_before:.6f}\")\n",
    "print(f\"After Calibration  - Val LogLoss: {logloss_after:.6f}\")\n",
    "print(f\"Final submission saved with calibration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9478c2",
   "metadata": {},
   "source": [
    "### Candidate 2: PLM + LightGBM(XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72c4d4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding model: ./models/e5-base-v2\n",
      "try: ./models/e5-base-v2\n",
      "loaded model from: ./models/e5-base-v2\n",
      "Encoding texts\n",
      "Prompt encoding complete.\n",
      "Response A encoding complete.\n",
      "Response B encoding complete.\n",
      "Encoding test data...\n",
      "Test encoding complete.\n",
      "Feature extraction complete. Time taken: 1465.02s\n",
      "Train features shape (X_c2): (57477, 6144)\n",
      "Test features shape (X_test_c2): (3, 6144)\n",
      "Data split into: Train (45981, 6144), Validation (11496, 6144)\n"
     ]
    }
   ],
   "source": [
    "### Candidate 2: PLM + LightGBM(XGBoost) ###\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import joblib # For saving models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Choose the model to run: \"LGBM\" or \"XGBOOST\"\n",
    "\n",
    "MODEL_NAME = \"e5-base-v2\" \n",
    "BEST_EMBEDDING_MODEL_PATH = f\"./models/{MODEL_NAME}\"\n",
    "print(f\"Using embedding model: {BEST_EMBEDDING_MODEL_PATH}\")\n",
    "\n",
    "# Load the chosen embedding model\n",
    "try:\n",
    "    # We pass a list containing only our chosen model path\n",
    "    sbert_model, model_src = load_model([BEST_EMBEDDING_MODEL_PATH], idx=0, device=device)\n",
    "    # print(f\"Successfully loaded model from: {model_src}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model from {BEST_EMBEDDING_MODEL_PATH}. Error: {e}\")\n",
    "\n",
    "print(\"Encoding texts\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Encode training data\n",
    "prompt_emb = encode_texts(sbert_model, train[\"prompt\"])\n",
    "print(\"Prompt encoding complete.\")\n",
    "a_emb = encode_texts(sbert_model, train[\"response_a\"])\n",
    "print(\"Response A encoding complete.\")\n",
    "b_emb = encode_texts(sbert_model, train[\"response_b\"])\n",
    "print(\"Response B encoding complete.\")\n",
    "\n",
    "# Build training features\n",
    "X_c2 = build_feat(prompt_emb, a_emb, b_emb) # X for candidate 2\n",
    "\n",
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "prompt_emb_te = encode_texts(sbert_model, test[\"prompt\"])\n",
    "a_emb_te = encode_texts(sbert_model, test[\"response_a\"])\n",
    "b_emb_te = encode_texts(sbert_model, test[\"response_b\"])\n",
    "print(\"Test encoding complete.\")\n",
    "\n",
    "# Build test features\n",
    "X_test_c2 = build_feat(prompt_emb_te, a_emb_te, b_emb_te)\n",
    "\n",
    "# Clean up model from memory\n",
    "del sbert_model, prompt_emb, a_emb, b_emb, prompt_emb_te, a_emb_te, b_emb_te\n",
    "\n",
    "print(f\"Feature extraction complete. Time taken: {time.time() - start_time:.2f}s\")\n",
    "print(f\"Train features shape (X_c2): {X_c2.shape}\")\n",
    "print(f\"Test features shape (X_test_c2): {X_test_c2.shape}\")\n",
    "\n",
    "# Create Train/Validation Split\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_c2, y, test_size=val_size, stratify=y, random_state=random_state)\n",
    "print(f\"Data split into: Train {X_tr.shape}, Validation {X_va.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1cf3dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Candidate 2: LGBM ---\n",
      "Model will be saved to: ./models/candidate_2_lgbm_e5-base-v2.pkl\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Warning] Metric multi_logloss is not implemented in cuda version. Fall back to evaluation on CPU.\n",
      "[LightGBM] [Info] Total Bins 1566720\n",
      "[LightGBM] [Info] Number of data points in the train set: 45981, number of used features: 6144\n",
      "[LightGBM] [Warning] Metric multi_logloss is not implemented in cuda version. Fall back to evaluation on CPU.\n",
      "[LightGBM] [Info] Start training from score -1.052457\n",
      "[LightGBM] [Info] Start training from score -1.073231\n",
      "[LightGBM] [Info] Start training from score -1.174353\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's multi_logloss: 1.03351\n",
      "--- LGBM Validation LogLoss: 1.033509 ---\n",
      "Training complete. Time taken: 527.87s\n",
      "Model saved to: ./models/candidate_2_lgbm_e5-base-v2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/jun_cls/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Path to save the trained GBM model\n",
    "GBM_CHOICE = \"LGBM\" \n",
    "CANDIDATE_2_MODEL_SAVE_PATH = f\"./models/candidate_2_{GBM_CHOICE.lower()}_{BEST_EMBEDDING_MODEL_PATH.split('/')[-1]}.pkl\"\n",
    "print(f\"--- Candidate 2: {GBM_CHOICE} ---\")\n",
    "print(f\"Model will be saved to: {CANDIDATE_2_MODEL_SAVE_PATH}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# This dictionary will hold the best validation logloss\n",
    "val_logloss = {}\n",
    "clf_c2 = None\n",
    "\n",
    "if GBM_CHOICE == \"LGBM\":\n",
    "    # --- 2.1. LightGBM ---\n",
    "    clf_c2 = lgb.LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        metric='multi_logloss',\n",
    "        num_class=3,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "        # device='gpu' if device == 'cuda' else 'cpu'\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    clf_c2.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        eval_metric='multi_logloss',\n",
    "        callbacks=[lgb.early_stopping(100, verbose=True)]\n",
    "    )\n",
    "    \n",
    "    va_pred = clf_c2.predict_proba(X_va)\n",
    "    val_logloss['LGBM'] = log_loss(y_va, va_pred)\n",
    "    print(f\"--- LGBM Validation LogLoss: {val_logloss['LGBM']:.6f} ---\")\n",
    "\n",
    "elif GBM_CHOICE == \"XGBOOST\":\n",
    "    # --- 2.2. XGBoost ---\n",
    "    clf_c2 = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        eval_metric='mlogloss',\n",
    "        num_class=3,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "        device=device,\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "    \n",
    "    clf_c2.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    va_pred = clf_c2.predict_proba(X_va)\n",
    "    val_logloss['XGBOOST'] = log_loss(y_va, va_pred)\n",
    "    print(f\"--- XGBOOST Validation LogLoss: {val_logloss['XGBOOST']:.6f} ---\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unknown GBM_CHOICE '{GBM_CHOICE}'. Please set to 'LGBM' or 'XGBOOST'.\")\n",
    "\n",
    "print(f\"Training complete. Time taken: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if clf_c2 is not None:\n",
    "    # Use joblib for cross-compatibility between LGBM/XGB\n",
    "    joblib.dump(clf_c2, CANDIDATE_2_MODEL_SAVE_PATH)\n",
    "    print(f\"Model saved to: {CANDIDATE_2_MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43264750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Candidate 2: XGBOOST ---\n",
      "Model will be saved to: ./models/candidate_2_xgboost_e5-base-v2.pkl\n",
      "[0]\tvalidation_0-mlogloss:1.09635\n",
      "[1]\tvalidation_0-mlogloss:1.09427\n",
      "[2]\tvalidation_0-mlogloss:1.09219\n",
      "[3]\tvalidation_0-mlogloss:1.09043\n",
      "[4]\tvalidation_0-mlogloss:1.08872\n",
      "[5]\tvalidation_0-mlogloss:1.08706\n",
      "[6]\tvalidation_0-mlogloss:1.08541\n",
      "[7]\tvalidation_0-mlogloss:1.08398\n",
      "[8]\tvalidation_0-mlogloss:1.08247\n",
      "[9]\tvalidation_0-mlogloss:1.08107\n",
      "[10]\tvalidation_0-mlogloss:1.07967\n",
      "[11]\tvalidation_0-mlogloss:1.07837\n",
      "[12]\tvalidation_0-mlogloss:1.07707\n",
      "[13]\tvalidation_0-mlogloss:1.07584\n",
      "[14]\tvalidation_0-mlogloss:1.07469\n",
      "[15]\tvalidation_0-mlogloss:1.07350\n",
      "[16]\tvalidation_0-mlogloss:1.07261\n",
      "[17]\tvalidation_0-mlogloss:1.07167\n",
      "[18]\tvalidation_0-mlogloss:1.07075\n",
      "[19]\tvalidation_0-mlogloss:1.06978\n",
      "[20]\tvalidation_0-mlogloss:1.06879\n",
      "[21]\tvalidation_0-mlogloss:1.06788\n",
      "[22]\tvalidation_0-mlogloss:1.06699\n",
      "[23]\tvalidation_0-mlogloss:1.06616\n",
      "[24]\tvalidation_0-mlogloss:1.06532\n",
      "[25]\tvalidation_0-mlogloss:1.06454\n",
      "[26]\tvalidation_0-mlogloss:1.06380\n",
      "[27]\tvalidation_0-mlogloss:1.06300\n",
      "[28]\tvalidation_0-mlogloss:1.06233\n",
      "[29]\tvalidation_0-mlogloss:1.06138\n",
      "[30]\tvalidation_0-mlogloss:1.06071\n",
      "[31]\tvalidation_0-mlogloss:1.06004\n",
      "[32]\tvalidation_0-mlogloss:1.05930\n",
      "[33]\tvalidation_0-mlogloss:1.05868\n",
      "[34]\tvalidation_0-mlogloss:1.05811\n",
      "[35]\tvalidation_0-mlogloss:1.05760\n",
      "[36]\tvalidation_0-mlogloss:1.05713\n",
      "[37]\tvalidation_0-mlogloss:1.05655\n",
      "[38]\tvalidation_0-mlogloss:1.05600\n",
      "[39]\tvalidation_0-mlogloss:1.05553\n",
      "[40]\tvalidation_0-mlogloss:1.05501\n",
      "[41]\tvalidation_0-mlogloss:1.05454\n",
      "[42]\tvalidation_0-mlogloss:1.05419\n",
      "[43]\tvalidation_0-mlogloss:1.05374\n",
      "[44]\tvalidation_0-mlogloss:1.05318\n",
      "[45]\tvalidation_0-mlogloss:1.05289\n",
      "[46]\tvalidation_0-mlogloss:1.05246\n",
      "[47]\tvalidation_0-mlogloss:1.05213\n",
      "[48]\tvalidation_0-mlogloss:1.05187\n",
      "[49]\tvalidation_0-mlogloss:1.05153\n",
      "[50]\tvalidation_0-mlogloss:1.05114\n",
      "[51]\tvalidation_0-mlogloss:1.05072\n",
      "[52]\tvalidation_0-mlogloss:1.05041\n",
      "[53]\tvalidation_0-mlogloss:1.05010\n",
      "[54]\tvalidation_0-mlogloss:1.04964\n",
      "[55]\tvalidation_0-mlogloss:1.04945\n",
      "[56]\tvalidation_0-mlogloss:1.04920\n",
      "[57]\tvalidation_0-mlogloss:1.04896\n",
      "[58]\tvalidation_0-mlogloss:1.04863\n",
      "[59]\tvalidation_0-mlogloss:1.04832\n",
      "[60]\tvalidation_0-mlogloss:1.04802\n",
      "[61]\tvalidation_0-mlogloss:1.04785\n",
      "[62]\tvalidation_0-mlogloss:1.04766\n",
      "[63]\tvalidation_0-mlogloss:1.04737\n",
      "[64]\tvalidation_0-mlogloss:1.04706\n",
      "[65]\tvalidation_0-mlogloss:1.04679\n",
      "[66]\tvalidation_0-mlogloss:1.04653\n",
      "[67]\tvalidation_0-mlogloss:1.04624\n",
      "[68]\tvalidation_0-mlogloss:1.04594\n",
      "[69]\tvalidation_0-mlogloss:1.04572\n",
      "[70]\tvalidation_0-mlogloss:1.04556\n",
      "[71]\tvalidation_0-mlogloss:1.04541\n",
      "[72]\tvalidation_0-mlogloss:1.04509\n",
      "[73]\tvalidation_0-mlogloss:1.04493\n",
      "[74]\tvalidation_0-mlogloss:1.04481\n",
      "[75]\tvalidation_0-mlogloss:1.04462\n",
      "[76]\tvalidation_0-mlogloss:1.04437\n",
      "[77]\tvalidation_0-mlogloss:1.04423\n",
      "[78]\tvalidation_0-mlogloss:1.04405\n",
      "[79]\tvalidation_0-mlogloss:1.04383\n",
      "[80]\tvalidation_0-mlogloss:1.04363\n",
      "[81]\tvalidation_0-mlogloss:1.04362\n",
      "[82]\tvalidation_0-mlogloss:1.04355\n",
      "[83]\tvalidation_0-mlogloss:1.04334\n",
      "[84]\tvalidation_0-mlogloss:1.04322\n",
      "[85]\tvalidation_0-mlogloss:1.04301\n",
      "[86]\tvalidation_0-mlogloss:1.04292\n",
      "[87]\tvalidation_0-mlogloss:1.04276\n",
      "[88]\tvalidation_0-mlogloss:1.04256\n",
      "[89]\tvalidation_0-mlogloss:1.04242\n",
      "[90]\tvalidation_0-mlogloss:1.04235\n",
      "[91]\tvalidation_0-mlogloss:1.04221\n",
      "[92]\tvalidation_0-mlogloss:1.04202\n",
      "[93]\tvalidation_0-mlogloss:1.04182\n",
      "[94]\tvalidation_0-mlogloss:1.04175\n",
      "[95]\tvalidation_0-mlogloss:1.04168\n",
      "[96]\tvalidation_0-mlogloss:1.04160\n",
      "[97]\tvalidation_0-mlogloss:1.04146\n",
      "[98]\tvalidation_0-mlogloss:1.04132\n",
      "[99]\tvalidation_0-mlogloss:1.04122\n",
      "[100]\tvalidation_0-mlogloss:1.04104\n",
      "[101]\tvalidation_0-mlogloss:1.04092\n",
      "[102]\tvalidation_0-mlogloss:1.04085\n",
      "[103]\tvalidation_0-mlogloss:1.04067\n",
      "[104]\tvalidation_0-mlogloss:1.04070\n",
      "[105]\tvalidation_0-mlogloss:1.04050\n",
      "[106]\tvalidation_0-mlogloss:1.04044\n",
      "[107]\tvalidation_0-mlogloss:1.04034\n",
      "[108]\tvalidation_0-mlogloss:1.04011\n",
      "[109]\tvalidation_0-mlogloss:1.04007\n",
      "[110]\tvalidation_0-mlogloss:1.04004\n",
      "[111]\tvalidation_0-mlogloss:1.03998\n",
      "[112]\tvalidation_0-mlogloss:1.03987\n",
      "[113]\tvalidation_0-mlogloss:1.03973\n",
      "[114]\tvalidation_0-mlogloss:1.03969\n",
      "[115]\tvalidation_0-mlogloss:1.03953\n",
      "[116]\tvalidation_0-mlogloss:1.03936\n",
      "[117]\tvalidation_0-mlogloss:1.03924\n",
      "[118]\tvalidation_0-mlogloss:1.03925\n",
      "[119]\tvalidation_0-mlogloss:1.03915\n",
      "[120]\tvalidation_0-mlogloss:1.03904\n",
      "[121]\tvalidation_0-mlogloss:1.03908\n",
      "[122]\tvalidation_0-mlogloss:1.03896\n",
      "[123]\tvalidation_0-mlogloss:1.03889\n",
      "[124]\tvalidation_0-mlogloss:1.03877\n",
      "[125]\tvalidation_0-mlogloss:1.03867\n",
      "[126]\tvalidation_0-mlogloss:1.03857\n",
      "[127]\tvalidation_0-mlogloss:1.03858\n",
      "[128]\tvalidation_0-mlogloss:1.03844\n",
      "[129]\tvalidation_0-mlogloss:1.03844\n",
      "[130]\tvalidation_0-mlogloss:1.03842\n",
      "[131]\tvalidation_0-mlogloss:1.03838\n",
      "[132]\tvalidation_0-mlogloss:1.03822\n",
      "[133]\tvalidation_0-mlogloss:1.03815\n",
      "[134]\tvalidation_0-mlogloss:1.03810\n",
      "[135]\tvalidation_0-mlogloss:1.03804\n",
      "[136]\tvalidation_0-mlogloss:1.03793\n",
      "[137]\tvalidation_0-mlogloss:1.03797\n",
      "[138]\tvalidation_0-mlogloss:1.03795\n",
      "[139]\tvalidation_0-mlogloss:1.03787\n",
      "[140]\tvalidation_0-mlogloss:1.03786\n",
      "[141]\tvalidation_0-mlogloss:1.03778\n",
      "[142]\tvalidation_0-mlogloss:1.03762\n",
      "[143]\tvalidation_0-mlogloss:1.03766\n",
      "[144]\tvalidation_0-mlogloss:1.03761\n",
      "[145]\tvalidation_0-mlogloss:1.03751\n",
      "[146]\tvalidation_0-mlogloss:1.03753\n",
      "[147]\tvalidation_0-mlogloss:1.03747\n",
      "[148]\tvalidation_0-mlogloss:1.03747\n",
      "[149]\tvalidation_0-mlogloss:1.03755\n",
      "[150]\tvalidation_0-mlogloss:1.03757\n",
      "[151]\tvalidation_0-mlogloss:1.03751\n",
      "[152]\tvalidation_0-mlogloss:1.03753\n",
      "[153]\tvalidation_0-mlogloss:1.03751\n",
      "[154]\tvalidation_0-mlogloss:1.03751\n",
      "[155]\tvalidation_0-mlogloss:1.03751\n",
      "[156]\tvalidation_0-mlogloss:1.03749\n",
      "[157]\tvalidation_0-mlogloss:1.03745\n",
      "[158]\tvalidation_0-mlogloss:1.03729\n",
      "[159]\tvalidation_0-mlogloss:1.03722\n",
      "[160]\tvalidation_0-mlogloss:1.03711\n",
      "[161]\tvalidation_0-mlogloss:1.03700\n",
      "[162]\tvalidation_0-mlogloss:1.03695\n",
      "[163]\tvalidation_0-mlogloss:1.03699\n",
      "[164]\tvalidation_0-mlogloss:1.03692\n",
      "[165]\tvalidation_0-mlogloss:1.03691\n",
      "[166]\tvalidation_0-mlogloss:1.03683\n",
      "[167]\tvalidation_0-mlogloss:1.03674\n",
      "[168]\tvalidation_0-mlogloss:1.03681\n",
      "[169]\tvalidation_0-mlogloss:1.03680\n",
      "[170]\tvalidation_0-mlogloss:1.03682\n",
      "[171]\tvalidation_0-mlogloss:1.03681\n",
      "[172]\tvalidation_0-mlogloss:1.03683\n",
      "[173]\tvalidation_0-mlogloss:1.03681\n",
      "[174]\tvalidation_0-mlogloss:1.03673\n",
      "[175]\tvalidation_0-mlogloss:1.03673\n",
      "[176]\tvalidation_0-mlogloss:1.03681\n",
      "[177]\tvalidation_0-mlogloss:1.03680\n",
      "[178]\tvalidation_0-mlogloss:1.03683\n",
      "[179]\tvalidation_0-mlogloss:1.03682\n",
      "[180]\tvalidation_0-mlogloss:1.03679\n",
      "[181]\tvalidation_0-mlogloss:1.03680\n",
      "[182]\tvalidation_0-mlogloss:1.03681\n",
      "[183]\tvalidation_0-mlogloss:1.03675\n",
      "[184]\tvalidation_0-mlogloss:1.03679\n",
      "[185]\tvalidation_0-mlogloss:1.03671\n",
      "[186]\tvalidation_0-mlogloss:1.03671\n",
      "[187]\tvalidation_0-mlogloss:1.03672\n",
      "[188]\tvalidation_0-mlogloss:1.03675\n",
      "[189]\tvalidation_0-mlogloss:1.03672\n",
      "[190]\tvalidation_0-mlogloss:1.03660\n",
      "[191]\tvalidation_0-mlogloss:1.03658\n",
      "[192]\tvalidation_0-mlogloss:1.03659\n",
      "[193]\tvalidation_0-mlogloss:1.03659\n",
      "[194]\tvalidation_0-mlogloss:1.03658\n",
      "[195]\tvalidation_0-mlogloss:1.03656\n",
      "[196]\tvalidation_0-mlogloss:1.03652\n",
      "[197]\tvalidation_0-mlogloss:1.03657\n",
      "[198]\tvalidation_0-mlogloss:1.03649\n",
      "[199]\tvalidation_0-mlogloss:1.03640\n",
      "[200]\tvalidation_0-mlogloss:1.03642\n",
      "[201]\tvalidation_0-mlogloss:1.03648\n",
      "[202]\tvalidation_0-mlogloss:1.03641\n",
      "[203]\tvalidation_0-mlogloss:1.03643\n",
      "[204]\tvalidation_0-mlogloss:1.03643\n",
      "[205]\tvalidation_0-mlogloss:1.03637\n",
      "[206]\tvalidation_0-mlogloss:1.03632\n",
      "[207]\tvalidation_0-mlogloss:1.03633\n",
      "[208]\tvalidation_0-mlogloss:1.03639\n",
      "[209]\tvalidation_0-mlogloss:1.03638\n",
      "[210]\tvalidation_0-mlogloss:1.03636\n",
      "[211]\tvalidation_0-mlogloss:1.03637\n",
      "[212]\tvalidation_0-mlogloss:1.03638\n",
      "[213]\tvalidation_0-mlogloss:1.03647\n",
      "[214]\tvalidation_0-mlogloss:1.03648\n",
      "[215]\tvalidation_0-mlogloss:1.03643\n",
      "[216]\tvalidation_0-mlogloss:1.03639\n",
      "[217]\tvalidation_0-mlogloss:1.03637\n",
      "[218]\tvalidation_0-mlogloss:1.03640\n",
      "[219]\tvalidation_0-mlogloss:1.03641\n",
      "[220]\tvalidation_0-mlogloss:1.03644\n",
      "[221]\tvalidation_0-mlogloss:1.03648\n",
      "[222]\tvalidation_0-mlogloss:1.03640\n",
      "[223]\tvalidation_0-mlogloss:1.03638\n",
      "[224]\tvalidation_0-mlogloss:1.03639\n",
      "[225]\tvalidation_0-mlogloss:1.03643\n",
      "[226]\tvalidation_0-mlogloss:1.03639\n",
      "[227]\tvalidation_0-mlogloss:1.03640\n",
      "[228]\tvalidation_0-mlogloss:1.03633\n",
      "[229]\tvalidation_0-mlogloss:1.03631\n",
      "[230]\tvalidation_0-mlogloss:1.03627\n",
      "[231]\tvalidation_0-mlogloss:1.03629\n",
      "[232]\tvalidation_0-mlogloss:1.03626\n",
      "[233]\tvalidation_0-mlogloss:1.03631\n",
      "[234]\tvalidation_0-mlogloss:1.03627\n",
      "[235]\tvalidation_0-mlogloss:1.03621\n",
      "[236]\tvalidation_0-mlogloss:1.03628\n",
      "[237]\tvalidation_0-mlogloss:1.03628\n",
      "[238]\tvalidation_0-mlogloss:1.03616\n",
      "[239]\tvalidation_0-mlogloss:1.03616\n",
      "[240]\tvalidation_0-mlogloss:1.03613\n",
      "[241]\tvalidation_0-mlogloss:1.03616\n",
      "[242]\tvalidation_0-mlogloss:1.03617\n",
      "[243]\tvalidation_0-mlogloss:1.03621\n",
      "[244]\tvalidation_0-mlogloss:1.03618\n",
      "[245]\tvalidation_0-mlogloss:1.03617\n",
      "[246]\tvalidation_0-mlogloss:1.03615\n",
      "[247]\tvalidation_0-mlogloss:1.03620\n",
      "[248]\tvalidation_0-mlogloss:1.03624\n",
      "[249]\tvalidation_0-mlogloss:1.03621\n",
      "[250]\tvalidation_0-mlogloss:1.03619\n",
      "[251]\tvalidation_0-mlogloss:1.03622\n",
      "[252]\tvalidation_0-mlogloss:1.03628\n",
      "[253]\tvalidation_0-mlogloss:1.03623\n",
      "[254]\tvalidation_0-mlogloss:1.03623\n",
      "[255]\tvalidation_0-mlogloss:1.03622\n",
      "[256]\tvalidation_0-mlogloss:1.03622\n",
      "[257]\tvalidation_0-mlogloss:1.03615\n",
      "[258]\tvalidation_0-mlogloss:1.03608\n",
      "[259]\tvalidation_0-mlogloss:1.03606\n",
      "[260]\tvalidation_0-mlogloss:1.03610\n",
      "[261]\tvalidation_0-mlogloss:1.03614\n",
      "[262]\tvalidation_0-mlogloss:1.03611\n",
      "[263]\tvalidation_0-mlogloss:1.03609\n",
      "[264]\tvalidation_0-mlogloss:1.03607\n",
      "[265]\tvalidation_0-mlogloss:1.03609\n",
      "[266]\tvalidation_0-mlogloss:1.03607\n",
      "[267]\tvalidation_0-mlogloss:1.03609\n",
      "[268]\tvalidation_0-mlogloss:1.03603\n",
      "[269]\tvalidation_0-mlogloss:1.03611\n",
      "[270]\tvalidation_0-mlogloss:1.03609\n",
      "[271]\tvalidation_0-mlogloss:1.03608\n",
      "[272]\tvalidation_0-mlogloss:1.03607\n",
      "[273]\tvalidation_0-mlogloss:1.03613\n",
      "[274]\tvalidation_0-mlogloss:1.03615\n",
      "[275]\tvalidation_0-mlogloss:1.03616\n",
      "[276]\tvalidation_0-mlogloss:1.03619\n",
      "[277]\tvalidation_0-mlogloss:1.03613\n",
      "[278]\tvalidation_0-mlogloss:1.03611\n",
      "[279]\tvalidation_0-mlogloss:1.03604\n",
      "[280]\tvalidation_0-mlogloss:1.03602\n",
      "[281]\tvalidation_0-mlogloss:1.03595\n",
      "[282]\tvalidation_0-mlogloss:1.03594\n",
      "[283]\tvalidation_0-mlogloss:1.03597\n",
      "[284]\tvalidation_0-mlogloss:1.03603\n",
      "[285]\tvalidation_0-mlogloss:1.03602\n",
      "[286]\tvalidation_0-mlogloss:1.03595\n",
      "[287]\tvalidation_0-mlogloss:1.03593\n",
      "[288]\tvalidation_0-mlogloss:1.03592\n",
      "[289]\tvalidation_0-mlogloss:1.03589\n",
      "[290]\tvalidation_0-mlogloss:1.03588\n",
      "[291]\tvalidation_0-mlogloss:1.03590\n",
      "[292]\tvalidation_0-mlogloss:1.03595\n",
      "[293]\tvalidation_0-mlogloss:1.03591\n",
      "[294]\tvalidation_0-mlogloss:1.03584\n",
      "[295]\tvalidation_0-mlogloss:1.03591\n",
      "[296]\tvalidation_0-mlogloss:1.03586\n",
      "[297]\tvalidation_0-mlogloss:1.03579\n",
      "[298]\tvalidation_0-mlogloss:1.03576\n",
      "[299]\tvalidation_0-mlogloss:1.03581\n",
      "[300]\tvalidation_0-mlogloss:1.03576\n",
      "[301]\tvalidation_0-mlogloss:1.03577\n",
      "[302]\tvalidation_0-mlogloss:1.03585\n",
      "[303]\tvalidation_0-mlogloss:1.03588\n",
      "[304]\tvalidation_0-mlogloss:1.03586\n",
      "[305]\tvalidation_0-mlogloss:1.03587\n",
      "[306]\tvalidation_0-mlogloss:1.03588\n",
      "[307]\tvalidation_0-mlogloss:1.03590\n",
      "[308]\tvalidation_0-mlogloss:1.03587\n",
      "[309]\tvalidation_0-mlogloss:1.03584\n",
      "[310]\tvalidation_0-mlogloss:1.03594\n",
      "[311]\tvalidation_0-mlogloss:1.03587\n",
      "[312]\tvalidation_0-mlogloss:1.03585\n",
      "[313]\tvalidation_0-mlogloss:1.03580\n",
      "[314]\tvalidation_0-mlogloss:1.03580\n",
      "[315]\tvalidation_0-mlogloss:1.03578\n",
      "[316]\tvalidation_0-mlogloss:1.03579\n",
      "[317]\tvalidation_0-mlogloss:1.03587\n",
      "[318]\tvalidation_0-mlogloss:1.03583\n",
      "[319]\tvalidation_0-mlogloss:1.03585\n",
      "[320]\tvalidation_0-mlogloss:1.03585\n",
      "[321]\tvalidation_0-mlogloss:1.03589\n",
      "[322]\tvalidation_0-mlogloss:1.03590\n",
      "[323]\tvalidation_0-mlogloss:1.03585\n",
      "[324]\tvalidation_0-mlogloss:1.03582\n",
      "[325]\tvalidation_0-mlogloss:1.03590\n",
      "[326]\tvalidation_0-mlogloss:1.03587\n",
      "[327]\tvalidation_0-mlogloss:1.03588\n",
      "[328]\tvalidation_0-mlogloss:1.03593\n",
      "[329]\tvalidation_0-mlogloss:1.03600\n",
      "[330]\tvalidation_0-mlogloss:1.03606\n",
      "[331]\tvalidation_0-mlogloss:1.03609\n",
      "[332]\tvalidation_0-mlogloss:1.03602\n",
      "[333]\tvalidation_0-mlogloss:1.03603\n",
      "[334]\tvalidation_0-mlogloss:1.03607\n",
      "[335]\tvalidation_0-mlogloss:1.03605\n",
      "[336]\tvalidation_0-mlogloss:1.03606\n",
      "[337]\tvalidation_0-mlogloss:1.03601\n",
      "[338]\tvalidation_0-mlogloss:1.03600\n",
      "[339]\tvalidation_0-mlogloss:1.03606\n",
      "[340]\tvalidation_0-mlogloss:1.03606\n",
      "[341]\tvalidation_0-mlogloss:1.03605\n",
      "[342]\tvalidation_0-mlogloss:1.03607\n",
      "[343]\tvalidation_0-mlogloss:1.03604\n",
      "[344]\tvalidation_0-mlogloss:1.03611\n",
      "[345]\tvalidation_0-mlogloss:1.03609\n",
      "[346]\tvalidation_0-mlogloss:1.03609\n",
      "[347]\tvalidation_0-mlogloss:1.03607\n",
      "[348]\tvalidation_0-mlogloss:1.03611\n",
      "[349]\tvalidation_0-mlogloss:1.03608\n",
      "[350]\tvalidation_0-mlogloss:1.03608\n",
      "[351]\tvalidation_0-mlogloss:1.03605\n",
      "[352]\tvalidation_0-mlogloss:1.03606\n",
      "[353]\tvalidation_0-mlogloss:1.03609\n",
      "[354]\tvalidation_0-mlogloss:1.03600\n",
      "[355]\tvalidation_0-mlogloss:1.03604\n",
      "[356]\tvalidation_0-mlogloss:1.03603\n",
      "[357]\tvalidation_0-mlogloss:1.03601\n",
      "[358]\tvalidation_0-mlogloss:1.03602\n",
      "[359]\tvalidation_0-mlogloss:1.03600\n",
      "[360]\tvalidation_0-mlogloss:1.03598\n",
      "[361]\tvalidation_0-mlogloss:1.03592\n",
      "[362]\tvalidation_0-mlogloss:1.03597\n",
      "[363]\tvalidation_0-mlogloss:1.03602\n",
      "[364]\tvalidation_0-mlogloss:1.03605\n",
      "[365]\tvalidation_0-mlogloss:1.03608\n",
      "[366]\tvalidation_0-mlogloss:1.03607\n",
      "[367]\tvalidation_0-mlogloss:1.03602\n",
      "[368]\tvalidation_0-mlogloss:1.03610\n",
      "[369]\tvalidation_0-mlogloss:1.03607\n",
      "[370]\tvalidation_0-mlogloss:1.03607\n",
      "[371]\tvalidation_0-mlogloss:1.03604\n",
      "[372]\tvalidation_0-mlogloss:1.03601\n",
      "[373]\tvalidation_0-mlogloss:1.03605\n",
      "[374]\tvalidation_0-mlogloss:1.03610\n",
      "[375]\tvalidation_0-mlogloss:1.03603\n",
      "[376]\tvalidation_0-mlogloss:1.03607\n",
      "[377]\tvalidation_0-mlogloss:1.03611\n",
      "[378]\tvalidation_0-mlogloss:1.03602\n",
      "[379]\tvalidation_0-mlogloss:1.03602\n",
      "[380]\tvalidation_0-mlogloss:1.03609\n",
      "[381]\tvalidation_0-mlogloss:1.03608\n",
      "[382]\tvalidation_0-mlogloss:1.03611\n",
      "[383]\tvalidation_0-mlogloss:1.03615\n",
      "[384]\tvalidation_0-mlogloss:1.03611\n",
      "[385]\tvalidation_0-mlogloss:1.03621\n",
      "[386]\tvalidation_0-mlogloss:1.03624\n",
      "[387]\tvalidation_0-mlogloss:1.03630\n",
      "[388]\tvalidation_0-mlogloss:1.03627\n",
      "[389]\tvalidation_0-mlogloss:1.03626\n",
      "[390]\tvalidation_0-mlogloss:1.03627\n",
      "[391]\tvalidation_0-mlogloss:1.03633\n",
      "[392]\tvalidation_0-mlogloss:1.03638\n",
      "[393]\tvalidation_0-mlogloss:1.03638\n",
      "[394]\tvalidation_0-mlogloss:1.03634\n",
      "[395]\tvalidation_0-mlogloss:1.03631\n",
      "[396]\tvalidation_0-mlogloss:1.03632\n",
      "[397]\tvalidation_0-mlogloss:1.03629\n",
      "[398]\tvalidation_0-mlogloss:1.03625\n",
      "[399]\tvalidation_0-mlogloss:1.03619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/jun_cls/lib/python3.10/site-packages/xgboost/core.py:705: UserWarning: [18:58:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1758008603490/work/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- XGBOOST Validation LogLoss: 1.035757 ---\n",
      "Training complete. Time taken: 120.73s\n",
      "Model saved to: ./models/candidate_2_xgboost_e5-base-v2.pkl\n"
     ]
    }
   ],
   "source": [
    "# Path to save the trained GBM model\n",
    "GBM_CHOICE = \"XGBOOST\" \n",
    "CANDIDATE_2_MODEL_SAVE_PATH = f\"./models/candidate_2_{GBM_CHOICE.lower()}_{BEST_EMBEDDING_MODEL_PATH.split('/')[-1]}.pkl\"\n",
    "print(f\"--- Candidate 2: {GBM_CHOICE} ---\")\n",
    "print(f\"Model will be saved to: {CANDIDATE_2_MODEL_SAVE_PATH}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# This dictionary will hold the best validation logloss\n",
    "val_logloss = {}\n",
    "clf_c2 = None\n",
    "\n",
    "if GBM_CHOICE == \"LGBM\":\n",
    "    # --- 2.1. LightGBM ---\n",
    "    clf_c2 = lgb.LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        metric='multi_logloss',\n",
    "        num_class=3,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "        # device='gpu' if device == 'cuda' else 'cpu'\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    clf_c2.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        eval_metric='multi_logloss',\n",
    "        callbacks=[lgb.early_stopping(100, verbose=True)]\n",
    "    )\n",
    "    \n",
    "    va_pred = clf_c2.predict_proba(X_va)\n",
    "    val_logloss['LGBM'] = log_loss(y_va, va_pred)\n",
    "    print(f\"--- LGBM Validation LogLoss: {val_logloss['LGBM']:.6f} ---\")\n",
    "\n",
    "elif GBM_CHOICE == \"XGBOOST\":\n",
    "    # --- 2.2. XGBoost ---\n",
    "    clf_c2 = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        eval_metric='mlogloss',\n",
    "        num_class=3,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "        device=device,\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "    \n",
    "    clf_c2.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    va_pred = clf_c2.predict_proba(X_va)\n",
    "    val_logloss['XGBOOST'] = log_loss(y_va, va_pred)\n",
    "    print(f\"--- XGBOOST Validation LogLoss: {val_logloss['XGBOOST']:.6f} ---\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unknown GBM_CHOICE '{GBM_CHOICE}'. Please set to 'LGBM' or 'XGBOOST'.\")\n",
    "\n",
    "print(f\"Training complete. Time taken: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "if clf_c2 is not None:\n",
    "    # Use joblib for cross-compatibility between LGBM/XGB\n",
    "    joblib.dump(clf_c2, CANDIDATE_2_MODEL_SAVE_PATH)\n",
    "    print(f\"Model saved to: {CANDIDATE_2_MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1fe713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Candidate 2 (XGBoost): Full Training & Submission ---\n",
      "Warning: 'best_iteration_' not found. Defaulting to 1000 estimators.\n",
      "Training full XGBOOST model with 1000 estimators...\n",
      "Full model trained.\n",
      "Full XGBOOST model saved to: ./models/candidate_2_XGBOOST_e5-base-v2_full.pkl\n",
      "Creating submission file: submission_candidate2_XGBOOST_e5-base-v2.csv...\n",
      "Successfully saved and verified: submission_candidate2_XGBOOST_e5-base-v2.csv (Shape: (3, 4))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.241118</td>\n",
       "      <td>0.446204</td>\n",
       "      <td>0.312677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.288413</td>\n",
       "      <td>0.355221</td>\n",
       "      <td>0.356366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.379745</td>\n",
       "      <td>0.376088</td>\n",
       "      <td>0.244166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.241118        0.446204    0.312677\n",
       "1   211333        0.288413        0.355221    0.356366\n",
       "2  1233961        0.379745        0.376088    0.244166"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- ADDED CELL: Candidate 2 Full Train & Submission ---\n",
    "\n",
    "print(\"\\n--- Candidate 2 (XGBoost): Full Training & Submission ---\")\n",
    "\n",
    "try:\n",
    "    best_iter = clf_c2.best_iteration_ or 1000\n",
    "except AttributeError:\n",
    "    print(\"Warning: 'best_iteration_' not found. Defaulting to 1000 estimators.\")\n",
    "    best_iter = 1000\n",
    "\n",
    "if GBM_CHOICE == \"LGBM\":\n",
    "    clf_c2_full = lgb.LGBMClassifier(\n",
    "        objective='multiclass', metric='multi_logloss', num_class=3,\n",
    "        n_estimators=best_iter, # Use best iteration from validation\n",
    "        learning_rate=0.05,\n",
    "        n_jobs=-1, random_state=random_state, device=device\n",
    "    )\n",
    "elif GBM_CHOICE == \"XGBOOST\":\n",
    "    clf_c2_full = xgb.XGBClassifier(\n",
    "    objective='multi:softprob', eval_metric='mlogloss', num_class=3,\n",
    "    n_estimators=best_iter, # Use best iteration from validation\n",
    "    learning_rate=0.05,\n",
    "    n_jobs=-1, random_state=random_state, device=device\n",
    "    )\n",
    "\n",
    "print(f\"Training full {GBM_CHOICE} model with {best_iter} estimators...\")\n",
    "# (Assumes X_c2 and y are the full datasets)\n",
    "clf_c2_full.fit(X_c2, y) \n",
    "print(\"Full model trained.\")\n",
    "\n",
    "# Predict on test set\n",
    "pred_c2_lgbm = clf_c2_full.predict_proba(X_test_c2) \n",
    "\n",
    "# Save submission\n",
    "GBM_SAVE_PATH = f\"./models/candidate_2_{GBM_CHOICE}_{MODEL_NAME}_full.pkl\"\n",
    "joblib.dump(clf_c2_full, GBM_SAVE_PATH)\n",
    "print(f\"Full {GBM_CHOICE} model saved to: {GBM_SAVE_PATH}\")\n",
    "\n",
    "create_and_save_submission(\n",
    "    predictions=pred_c2_lgbm,\n",
    "    filename=f\"submission_candidate2_{GBM_CHOICE}_{MODEL_NAME}.csv\",\n",
    "    test_df=test, sample_df=sample\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454b399",
   "metadata": {},
   "source": [
    "### Candidate 2: Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc172072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Candidate 2 (XGBoost): Calibration ===\n",
      "Validation LogLoss BEFORE Calibration: 1.035757\n",
      "Applying Isotonic calibration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/jun_cls/lib/python3.10/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation LogLoss AFTER Calibration: 1.030071\n",
      "Improvement: 0.005686\n",
      "\n",
      "Retraining on full data for final submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/jun_cls/lib/python3.10/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submission file: submission_candidate2_XGBOOST_e5-base-v2_CALIBRATED.csv...\n",
      "Successfully saved and verified: submission_candidate2_XGBOOST_e5-base-v2_CALIBRATED.csv (Shape: (3, 4))\n",
      "\n",
      "=== Candidate 2 Summary ===\n",
      "Before Calibration - Val LogLoss: 1.035757\n",
      "After Calibration  - Val LogLoss: 1.030071\n",
      "Final submission saved with calibration.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n=== Candidate 2 (XGBoost): Calibration ===\")\n",
    "\n",
    "# Get validation predictions BEFORE calibration\n",
    "# We need to recreate the train/val split from earlier\n",
    "X_tr_c2, X_va_c2, y_tr_c2, y_va_c2 = train_test_split(\n",
    "    X_c2, y, test_size=val_size, stratify=y, random_state=random_state\n",
    ")\n",
    "\n",
    "# Get predictions from the validation model (clf_c2 trained on X_tr, X_va split)\n",
    "if 'clf_c2' in locals() and clf_c2 is not None:\n",
    "    va_pred_before = clf_c2.predict_proba(X_va_c2)\n",
    "    logloss_before = log_loss(y_va_c2, va_pred_before)\n",
    "    print(f\"Validation LogLoss BEFORE Calibration: {logloss_before:.6f}\")\n",
    "    \n",
    "    # Apply calibration (using isotonic regression)\n",
    "    print(\"Applying Isotonic calibration...\")\n",
    "    calibrated_model_c2 = CalibratedClassifierCV(\n",
    "        clf_c2,\n",
    "        method='isotonic',  # isotonic or sigmoid\n",
    "        cv='prefit',  # Model is already fitted\n",
    "        ensemble=False\n",
    "    )\n",
    "    \n",
    "    # Fit calibration on validation set\n",
    "    calibrated_model_c2.fit(X_va_c2, y_va_c2)\n",
    "    \n",
    "    # Get calibrated predictions on validation set\n",
    "    va_pred_after = calibrated_model_c2.predict_proba(X_va_c2)\n",
    "    logloss_after = log_loss(y_va_c2, va_pred_after)\n",
    "    print(f\"Validation LogLoss AFTER Calibration: {logloss_after:.6f}\")\n",
    "    print(f\"Improvement: {logloss_before - logloss_after:.6f}\")\n",
    "    \n",
    "    # Now retrain on full data and apply calibration\n",
    "    print(\"\\nRetraining on full data for final submission...\")\n",
    "    \n",
    "    # Get best iteration\n",
    "    try:\n",
    "        best_iter = clf_c2.best_iteration_ or 1000\n",
    "    except AttributeError:\n",
    "        best_iter = 1000\n",
    "    \n",
    "    # Train on 80% of full data\n",
    "    X_train_full, X_cal, y_train_full, y_cal = train_test_split(\n",
    "        X_c2, y, test_size=0.2, stratify=y, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    if GBM_CHOICE == \"LGBM\":\n",
    "        clf_c2_for_calib = lgb.LGBMClassifier(\n",
    "            objective='multiclass', metric='multi_logloss', num_class=3,\n",
    "            n_estimators=best_iter, learning_rate=0.05,\n",
    "            n_jobs=-1, random_state=random_state, device=device\n",
    "        )\n",
    "    elif GBM_CHOICE == \"XGBOOST\":\n",
    "        clf_c2_for_calib = xgb.XGBClassifier(\n",
    "            objective='multi:softprob', eval_metric='mlogloss', num_class=3,\n",
    "            n_estimators=best_iter, learning_rate=0.05,\n",
    "            n_jobs=-1, random_state=random_state, device=device\n",
    "        )\n",
    "    \n",
    "    clf_c2_for_calib.fit(X_train_full, y_train_full)\n",
    "    \n",
    "    # Apply calibration on the hold-out 20%\n",
    "    calibrated_final_c2 = CalibratedClassifierCV(\n",
    "        clf_c2_for_calib,\n",
    "        method='isotonic',\n",
    "        cv='prefit',\n",
    "        ensemble=False\n",
    "    )\n",
    "    calibrated_final_c2.fit(X_cal, y_cal)\n",
    "    \n",
    "    # Predict on test set with calibration\n",
    "    pred_c2_calibrated = calibrated_final_c2.predict_proba(X_test_c2)\n",
    "    \n",
    "    # Save calibrated submission\n",
    "    create_and_save_submission(\n",
    "        predictions=pred_c2_calibrated,\n",
    "        filename=f\"submission_candidate2_{GBM_CHOICE}_{MODEL_NAME}_CALIBRATED.csv\",\n",
    "        test_df=test,\n",
    "        sample_df=sample\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n=== Candidate 2 Summary ===\")\n",
    "    print(f\"Before Calibration - Val LogLoss: {logloss_before:.6f}\")\n",
    "    print(f\"After Calibration  - Val LogLoss: {logloss_after:.6f}\")\n",
    "    print(f\"Final submission saved with calibration.\")\n",
    "else:\n",
    "    print(\"Error: clf_c2 model not found. Please run the training cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae5691",
   "metadata": {},
   "source": [
    "### Candidate 3: All Features + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160ce994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Candidate 3: All Features + MLP ---\n",
      "Building strong lexical features...\n",
      "Strong lexical features shape: (57477, 30)\n"
     ]
    }
   ],
   "source": [
    "### Candidate 3: All Features + MLP ###\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the \"Strong\" lexical feature builder\n",
    "def stats_strong(s):\n",
    "    \"\"\"Calculates a comprehensive set of lexical statistics.\"\"\"\n",
    "    if not isinstance(s, str): s = \"\"\n",
    "    toks = s.split()\n",
    "    return {\n",
    "        \"len_char\": len(s),\n",
    "        \"len_tok\": len(toks),\n",
    "        \"num_sent\": sum(s.count(x) for x in [\".\", \"!\", \"?\"]),\n",
    "        \"num_code\": s.count(\"`\"),\n",
    "        \"num_list\": s.count(\"- \") + s.count(\"* \"),\n",
    "        \"num_upper\": sum(ch.isupper() for ch in s),\n",
    "        \"num_punct\": sum(ch in \",;:()\" for ch in s),\n",
    "        \"avg_tok_len\": (sum(len(t) for t in toks) / len(toks)) if toks else 0.0,\n",
    "    }\n",
    "\n",
    "def build_strong_lexical_features(df):\n",
    "    \"\"\"Builds the full set of lexical and bias features.\"\"\"\n",
    "    rows = []\n",
    "    cols = [\"prompt\", \"response_a\", \"response_b\"]\n",
    "    \n",
    "    for p, a, b in zip(df[cols[0]], df[cols[1]], df[cols[2]]):\n",
    "        ps, as_, bs = stats_strong(p), stats_strong(a), stats_strong(b)\n",
    "        rows.append({\n",
    "            \"p_len_char\": ps[\"len_char\"], \"p_len_tok\": ps[\"len_tok\"], \"p_num_sent\": ps[\"num_sent\"],\n",
    "            \"a_len_char\": as_[\"len_char\"], \"a_len_tok\": as_[\"len_tok\"], \"a_num_sent\": as_[\"num_sent\"],\n",
    "            \"a_num_code\": as_[\"num_code\"], \"a_num_list\": as_[\"num_list\"], \"a_num_upper\": as_[\"num_upper\"],\n",
    "            \"a_num_punct\": as_[\"num_punct\"], \"a_avg_tok_len\": as_[\"avg_tok_len\"],\n",
    "            \"b_len_char\": bs[\"len_char\"], \"b_len_tok\": bs[\"len_tok\"], \"b_num_sent\": bs[\"num_sent\"],\n",
    "            \"b_num_code\": bs[\"num_code\"], \"b_num_list\": bs[\"num_list\"], \"b_num_upper\": bs[\"num_upper\"],\n",
    "            \"b_num_punct\": bs[\"num_punct\"], \"b_avg_tok_len\": bs[\"avg_tok_len\"],\n",
    "            # A-B Differences\n",
    "            \"d_len_char\": as_[\"len_char\"] - bs[\"len_char\"],\n",
    "            \"d_len_tok\": as_[\"len_tok\"] - bs[\"len_tok\"],\n",
    "            \"d_num_sent\": as_[\"num_sent\"] - bs[\"num_sent\"],\n",
    "            \"d_num_code\": as_[\"num_code\"] - bs[\"num_code\"],\n",
    "            \"d_num_list\": as_[\"num_list\"] - bs[\"num_list\"],\n",
    "            \"d_num_upper\": as_[\"num_upper\"] - bs[\"num_upper\"],\n",
    "            \"d_num_punct\": as_[\"num_punct\"] - bs[\"num_punct\"],\n",
    "            \"d_avg_tok_len\": as_[\"avg_tok_len\"] - bs[\"avg_tok_len\"],\n",
    "            # Ratios\n",
    "            \"r_len_char\": (as_[\"len_char\"] + 1) / (bs[\"len_char\"] + 1),\n",
    "            \"r_len_tok\": (as_[\"len_tok\"] + 1) / (bs[\"len_tok\"] + 1),\n",
    "            \"r_num_sent\": (as_[\"num_sent\"] + 1) / (bs[\"num_sent\"] + 1),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "print(\"--- Candidate 3: All Features + MLP ---\")\n",
    "print(\"Building strong lexical features...\")\n",
    "\n",
    "# Generate Lexical Features\n",
    "X_lex_strong = build_strong_lexical_features(train)\n",
    "X_test_lex_strong = build_strong_lexical_features(test)\n",
    "\n",
    "print(f\"Strong lexical features shape: {X_lex_strong.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d71772e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding model: ./models/e5-base-v2\n",
      "try: ./models/e5-base-v2\n",
      "loaded model from: ./models/e5-base-v2\n",
      "Encoding texts\n",
      "Prompt encoding complete.\n",
      "Response A encoding complete.\n",
      "Response B encoding complete.\n",
      "Encoding test data...\n",
      "Encoding complete for test data.\n",
      "Feature extraction complete. Time taken: 1461.08s\n",
      "Train features shape (X_c3): (57477, 6144)\n",
      "Test features shape (X_test_c3): (3, 6144)\n",
      "Data split into: Train (45981, 6144), Validation (11496, 6144)\n"
     ]
    }
   ],
   "source": [
    "import joblib # For saving models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"e5-base-v2\" \n",
    "BEST_EMBEDDING_MODEL_PATH = f\"./models/{MODEL_NAME}\"\n",
    "print(f\"Using embedding model: {BEST_EMBEDDING_MODEL_PATH}\")\n",
    "\n",
    "# Load the chosen embedding model\n",
    "try:\n",
    "    # We pass a list containing only our chosen model path\n",
    "    sbert_model, model_src = load_model([BEST_EMBEDDING_MODEL_PATH], idx=0, device=device)\n",
    "    # print(f\"Successfully loaded model from: {model_src}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model from {BEST_EMBEDDING_MODEL_PATH}. Error: {e}\")\n",
    "\n",
    "print(\"Encoding texts\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Encode training data\n",
    "prompt_emb = encode_texts(sbert_model, train[\"prompt\"])\n",
    "print(\"Prompt encoding complete.\")\n",
    "a_emb = encode_texts(sbert_model, train[\"response_a\"])\n",
    "print(\"Response A encoding complete.\")\n",
    "b_emb = encode_texts(sbert_model, train[\"response_b\"])\n",
    "print(\"Response B encoding complete.\")\n",
    "\n",
    "# Build training features\n",
    "X_c3 = build_feat(prompt_emb, a_emb, b_emb) # X for candidate 3\n",
    "\n",
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "prompt_emb_te = encode_texts(sbert_model, test[\"prompt\"])\n",
    "a_emb_te = encode_texts(sbert_model, test[\"response_a\"])\n",
    "b_emb_te = encode_texts(sbert_model, test[\"response_b\"])\n",
    "print(\"Encoding complete for test data.\")\n",
    "\n",
    "# Build test features\n",
    "X_test_c3 = build_feat(prompt_emb_te, a_emb_te, b_emb_te)\n",
    "\n",
    "# Clean up model from memory\n",
    "del sbert_model, prompt_emb, a_emb, b_emb, prompt_emb_te, a_emb_te, b_emb_te\n",
    "\n",
    "print(f\"Feature extraction complete. Time taken: {time.time() - start_time:.2f}s\")\n",
    "print(f\"Train features shape (X_c3): {X_c3.shape}\")\n",
    "print(f\"Test features shape (X_test_c3): {X_test_c3.shape}\")\n",
    "\n",
    "# Create Train/Validation Split\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_c3, y, test_size=val_size, stratify=y)\n",
    "print(f\"Data split into: Train {X_tr.shape}, Validation {X_va.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c98530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining lexical and embedding features...\n",
      "Combined train features shape (X_c3): (57477, 6174)\n",
      "Combined test features shape (X_test_c3): (3, 6174)\n",
      "Scaling features...\n",
      "Training MLPClassifier...\n",
      "Iteration 1, loss = 1.12600698\n",
      "Validation score: 0.463796\n",
      "Iteration 2, loss = 0.82086238\n",
      "Validation score: 0.447271\n",
      "Iteration 3, loss = 0.53996426\n",
      "Validation score: 0.430093\n",
      "Iteration 4, loss = 0.26805010\n",
      "Validation score: 0.429441\n",
      "Iteration 5, loss = 0.12704382\n",
      "Validation score: 0.448141\n",
      "Iteration 6, loss = 0.06509657\n",
      "Validation score: 0.437486\n",
      "Iteration 7, loss = 0.04185474\n",
      "Validation score: 0.436834\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Training complete. Time taken: 56.44s\n",
      "--- MLP (All Features) Validation LogLoss: 1.048909 ---\n",
      "MLP model saved to: ./models/candidate_3_mlp.pkl\n",
      "Scaler saved to: ./models/candidate_3_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Handle NaNs/Infs for safety\n",
    "X_lex_strong = X_lex_strong.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "X_test_lex_strong = X_test_lex_strong.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Convert embedding features (numpy) to DataFrame for safe processing\n",
    "X_c3_safe = pd.DataFrame(X_c3).fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "X_test_c3_safe = pd.DataFrame(X_test_c3).fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "\n",
    "print(\"Combining lexical and embedding features...\")\n",
    "X_c3 = np.hstack([X_lex_strong, X_c3_safe])\n",
    "X_test_c3 = np.hstack([X_test_lex_strong, X_test_c3_safe])\n",
    "print(f\"Combined train features shape (X_c3): {X_c3.shape}\")\n",
    "print(f\"Combined test features shape (X_test_c3): {X_test_c3.shape}\")\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_c3, y, test_size=val_size, stratify=y, random_state=random_state)\n",
    "\n",
    "print(\"Scaling features...\")\n",
    "scaler_c3 = StandardScaler()\n",
    "X_tr_sc = scaler_c3.fit_transform(X_tr)\n",
    "X_va_sc = scaler_c3.transform(X_va)\n",
    "\n",
    "# Train MLP Classifier\n",
    "print(\"Training MLPClassifier...\")\n",
    "start_time = time.time()\n",
    "\n",
    "clf_c3 = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,          # L2 regularization\n",
    "    batch_size=512,\n",
    "    learning_rate_init=1e-3,\n",
    "    max_iter=100,        \n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=5,\n",
    "    random_state=random_state,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "clf_c3.fit(X_tr_sc, y_tr)\n",
    "\n",
    "va_pred = clf_c3.predict_proba(X_va_sc)\n",
    "val_logloss = log_loss(y_va, va_pred)\n",
    "\n",
    "print(f\"Training complete. Time taken: {time.time() - start_time:.2f}s\")\n",
    "print(f\"--- MLP (All Features) Validation LogLoss: {val_logloss:.6f} ---\")\n",
    "\n",
    "CANDIDATE_3_MODEL_SAVE_PATH = \"./models/candidate_3_mlp.pkl\"\n",
    "CANDIDATE_3_SCALER_SAVE_PATH = \"./models/candidate_3_scaler.pkl\"\n",
    "\n",
    "joblib.dump(clf_c3, CANDIDATE_3_MODEL_SAVE_PATH)\n",
    "joblib.dump(scaler_c3, CANDIDATE_3_SCALER_SAVE_PATH)\n",
    "\n",
    "print(f\"MLP model saved to: {CANDIDATE_3_MODEL_SAVE_PATH}\")\n",
    "print(f\"Scaler saved to: {CANDIDATE_3_SCALER_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a108607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Candidate 3 (MLP): Full Training & Submission ---\n",
      "Scaling full dataset for submission...\n",
      "Training final MLP on ALL data...\n",
      "Iteration 1, loss = 1.10194019\n",
      "Validation score: 0.470424\n",
      "Iteration 2, loss = 0.87663369\n",
      "Validation score: 0.437717\n",
      "Iteration 3, loss = 0.68406746\n",
      "Validation score: 0.435978\n",
      "Iteration 4, loss = 0.45052073\n",
      "Validation score: 0.420842\n",
      "Iteration 5, loss = 0.26795151\n",
      "Validation score: 0.439631\n",
      "Iteration 6, loss = 0.13355633\n",
      "Validation score: 0.449374\n",
      "Iteration 7, loss = 0.07360602\n",
      "Validation score: 0.446938\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Full training complete. Time: 55.82s\n",
      "MLP (full) model saved to: ./models/candidate_3_mlp_full.pkl\n",
      "Scaler (full) saved to: ./models/candidate_3_scaler_full.pkl\n",
      "Creating submission file: submission_candidate3_MLP_AllFeatures.csv...\n",
      "Successfully saved and verified: submission_candidate3_MLP_AllFeatures.csv (Shape: (3, 4))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.205456</td>\n",
       "      <td>0.429275</td>\n",
       "      <td>0.365268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.431486</td>\n",
       "      <td>0.207630</td>\n",
       "      <td>0.360884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.226477</td>\n",
       "      <td>0.352537</td>\n",
       "      <td>0.420986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.205456        0.429275    0.365268\n",
       "1   211333        0.431486        0.207630    0.360884\n",
       "2  1233961        0.226477        0.352537    0.420986"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- ADDED CELL: Candidate 3 (MLP) Full Train & Submission ---\n",
    "# This cell assumes 'X_c3', 'X_test_c3', 'y', 'random_state', 'test', 'sample' exist.\n",
    "\n",
    "print(\"\\n--- Candidate 3 (MLP): Full Training & Submission ---\")\n",
    "\n",
    "# 1. Scale ALL data\n",
    "print(\"Scaling full dataset for submission...\")\n",
    "scaler_c3_full = StandardScaler()\n",
    "X_all_sc_c3 = scaler_c3_full.fit_transform(X_c3)\n",
    "X_test_sc_c3 = scaler_c3_full.transform(X_test_c3)\n",
    "\n",
    "# 2. Train new model on ALL data\n",
    "print(\"Training final MLP on ALL data...\")\n",
    "start_time_c3_full = time.time()\n",
    "clf_c3_full = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256), activation=\"relu\", solver=\"adam\",\n",
    "    alpha=1e-4, batch_size=512, learning_rate_init=1e-3,\n",
    "    max_iter=100, \n",
    "    early_stopping=True, n_iter_no_change=5, # Keep early stopping\n",
    "    random_state=random_state, verbose=True\n",
    ")\n",
    "clf_c3_full.fit(X_all_sc_c3, y) # Train on full X and y\n",
    "print(f\"Full training complete. Time: {time.time() - start_time_c3_full:.2f}s\")\n",
    "\n",
    "# 3. Save model and scaler\n",
    "CANDIDATE_3_MODEL_SAVE_PATH = \"./models/candidate_3_mlp_full.pkl\"\n",
    "CANDIDATE_3_SCALER_SAVE_PATH = \"./models/candidate_3_scaler_full.pkl\"\n",
    "joblib.dump(clf_c3_full, CANDIDATE_3_MODEL_SAVE_PATH)\n",
    "joblib.dump(scaler_c3_full, CANDIDATE_3_SCALER_SAVE_PATH)\n",
    "print(f\"MLP (full) model saved to: {CANDIDATE_3_MODEL_SAVE_PATH}\")\n",
    "print(f\"Scaler (full) saved to: {CANDIDATE_3_SCALER_SAVE_PATH}\")\n",
    "\n",
    "# 4. Predict and Save Submission\n",
    "pred_c3_full = clf_c3_full.predict_proba(X_test_sc_c3)\n",
    "create_and_save_submission(\n",
    "    predictions=pred_c3_full,\n",
    "    filename=f\"submission_candidate3_MLP_AllFeatures.csv\",\n",
    "    test_df=test,\n",
    "    sample_df=sample\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb882ccd",
   "metadata": {},
   "source": [
    "### Candidate 3: Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797e9f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Candidate 3 (MLP All Features): Calibration ===\n",
      "Validation LogLoss BEFORE Calibration: 1.048909\n",
      "Applying Isotonic calibration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/jun_cls/lib/python3.10/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation LogLoss AFTER Calibration: 1.036883\n",
      "Improvement: 0.012026\n",
      "\n",
      "Retraining on full data for final submission...\n",
      "Creating submission file: submission_candidate3_MLP_AllFeatures_CALIBRATED.csv...\n",
      "Successfully saved and verified: submission_candidate3_MLP_AllFeatures_CALIBRATED.csv (Shape: (3, 4))\n",
      "\n",
      "=== Candidate 3 Summary ===\n",
      "Before Calibration - Val LogLoss: 1.048909\n",
      "After Calibration  - Val LogLoss: 1.036883\n",
      "Final submission saved with calibration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/jun_cls/lib/python3.10/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n=== Candidate 3 (MLP All Features): Calibration ===\")\n",
    "\n",
    "# Get validation predictions BEFORE calibration\n",
    "# We need to recreate the train/val split from earlier\n",
    "X_tr_c3, X_va_c3, y_tr_c3, y_va_c3 = train_test_split(\n",
    "    X_c3, y, test_size=val_size, stratify=y, random_state=random_state\n",
    ")\n",
    "\n",
    "# Scale validation data\n",
    "scaler_c3_val = StandardScaler()\n",
    "X_tr_sc_c3 = scaler_c3_val.fit_transform(X_tr_c3)\n",
    "X_va_sc_c3 = scaler_c3_val.transform(X_va_c3)\n",
    "\n",
    "# Get predictions from the validation model (clf_c3 trained on X_tr, X_va split)\n",
    "if 'clf_c3' in locals() and clf_c3 is not None:\n",
    "    va_pred_before = clf_c3.predict_proba(X_va_sc_c3)\n",
    "    logloss_before = log_loss(y_va_c3, va_pred_before)\n",
    "    print(f\"Validation LogLoss BEFORE Calibration: {logloss_before:.6f}\")\n",
    "    \n",
    "    # Apply calibration (using isotonic regression)\n",
    "    print(\"Applying Isotonic calibration...\")\n",
    "    calibrated_model_c3 = CalibratedClassifierCV(\n",
    "        clf_c3,\n",
    "        method='isotonic',  # isotonic or sigmoid\n",
    "        cv='prefit',  # Model is already fitted\n",
    "        ensemble=False\n",
    "    )\n",
    "    \n",
    "    # Fit calibration on validation set\n",
    "    calibrated_model_c3.fit(X_va_sc_c3, y_va_c3)\n",
    "    \n",
    "    # Get calibrated predictions on validation set\n",
    "    va_pred_after = calibrated_model_c3.predict_proba(X_va_sc_c3)\n",
    "    logloss_after = log_loss(y_va_c3, va_pred_after)\n",
    "    print(f\"Validation LogLoss AFTER Calibration: {logloss_after:.6f}\")\n",
    "    print(f\"Improvement: {logloss_before - logloss_after:.6f}\")\n",
    "    \n",
    "    # Now retrain on full data and apply calibration\n",
    "    print(\"\\nRetraining on full data for final submission...\")\n",
    "    \n",
    "    # Train on 80% of full data\n",
    "    X_train_full, X_cal, y_train_full, y_cal = train_test_split(\n",
    "        X_c3, y, test_size=0.2, stratify=y, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Scale\n",
    "    scaler_final_c3 = StandardScaler()\n",
    "    X_train_full_sc = scaler_final_c3.fit_transform(X_train_full)\n",
    "    X_cal_sc = scaler_final_c3.transform(X_cal)\n",
    "    X_test_final_sc = scaler_final_c3.transform(X_test_c3)\n",
    "    \n",
    "    # Train MLP\n",
    "    clf_c3_for_calib = MLPClassifier(\n",
    "        hidden_layer_sizes=(512, 256), activation=\"relu\", solver=\"adam\",\n",
    "        alpha=1e-4, batch_size=512, learning_rate_init=1e-3,\n",
    "        max_iter=100, early_stopping=True, n_iter_no_change=5,\n",
    "        random_state=random_state, verbose=False\n",
    "    )\n",
    "    clf_c3_for_calib.fit(X_train_full_sc, y_train_full)\n",
    "    \n",
    "    # Apply calibration on the hold-out 20%\n",
    "    calibrated_final_c3 = CalibratedClassifierCV(\n",
    "        clf_c3_for_calib,\n",
    "        method='isotonic',\n",
    "        cv='prefit',\n",
    "        ensemble=False\n",
    "    )\n",
    "    calibrated_final_c3.fit(X_cal_sc, y_cal)\n",
    "    \n",
    "    # Predict on test set with calibration\n",
    "    pred_c3_calibrated = calibrated_final_c3.predict_proba(X_test_final_sc)\n",
    "    \n",
    "    # Save calibrated submission\n",
    "    create_and_save_submission(\n",
    "        predictions=pred_c3_calibrated,\n",
    "        filename=f\"submission_candidate3_MLP_AllFeatures_CALIBRATED.csv\",\n",
    "        test_df=test,\n",
    "        sample_df=sample\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n=== Candidate 3 Summary ===\")\n",
    "    print(f\"Before Calibration - Val LogLoss: {logloss_before:.6f}\")\n",
    "    print(f\"After Calibration  - Val LogLoss: {logloss_after:.6f}\")\n",
    "    print(f\"Final submission saved with calibration.\")\n",
    "else:\n",
    "    print(\"Error: clf_c3 model not found. Please run the training cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd10805",
   "metadata": {},
   "source": [
    "### Final Step. Final Model and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d73199f",
   "metadata": {},
   "source": [
    "### Final Ensemble: Advanced Strategies\n",
    "\n",
    "이 섹션에서는 Candidate 1, 2, 3의 calibrated predictions를 최적으로 결합합니다.\n",
    "\n",
    "**구현할 앙상블 전략:**\n",
    "1. **Simple Average** - 기준선\n",
    "2. **Weighted Average** - Validation 성능 기반 가중치\n",
    "3. **Stacked Generalization** - Meta-learner (Logistic Regression)\n",
    "4. **Optimal Weights (Grid Search)** - 최적 가중치 탐색\n",
    "5. **Rank Averaging** - 순위 기반 앙상블\n",
    "\n",
    "각 전략의 Validation Log Loss를 비교하여 최종 제출용 모델을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49cd7e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ADVANCED ENSEMBLE: Loading Calibrated Predictions\n",
      "================================================================================\n",
      "\n",
      "1) Candidate 1 (DeBERTa) validation predictions\n",
      "   Missing Candidate 1. Run the calibration cell.\n",
      "\n",
      "2) Candidate 2 (XGBoost/LGBM) validation predictions\n",
      "   OK shape: (11496, 3)\n",
      "   Val LogLoss: 1.030071\n",
      "\n",
      "3) Candidate 3 (MLP) validation predictions\n",
      "   OK shape: (11496, 3)\n",
      "   Val LogLoss: 1.036883\n",
      "\n",
      "================================================================================\n",
      "Individual Model Performance Summary\n",
      "   C2_XGBoost: 1.030071\n",
      "   C3_MLP: 1.036883\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# === Section 1. Imports and Validation Predictions (C1/C2/C3) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "import glob, os\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ADVANCED ENSEMBLE: Loading Calibrated Predictions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Candidate 1 (DeBERTa + LoRA)\n",
    "print(\"\\n1) Candidate 1 (DeBERTa) validation predictions\")\n",
    "if 'calibrated_model_c1' in locals() and calibrated_model_c1 is not None:\n",
    "    val_indices_c1 = np.arange(len(tokenized_val_dataset))\n",
    "    val_pred_c1 = calibrated_model_c1.predict_proba(val_indices_c1.reshape(-1, 1))\n",
    "    y_val_ensemble = val_df['labels'].values\n",
    "    print(f\"   OK shape: {val_pred_c1.shape}\")\n",
    "    print(f\"   Val LogLoss: {log_loss(y_val_ensemble, val_pred_c1):.6f}\")\n",
    "else:\n",
    "    print(\"   Missing Candidate 1. Run the calibration cell.\")\n",
    "    val_pred_c1 = None\n",
    "\n",
    "# Candidate 2 (XGBoost/LightGBM)\n",
    "print(\"\\n2) Candidate 2 (XGBoost/LGBM) validation predictions\")\n",
    "if 'X_c2' in locals() and 'calibrated_model_c2' in locals() and calibrated_model_c2 is not None:\n",
    "    X_tr_c2_ens, X_va_c2_ens, y_tr_c2_ens, y_va_c2_ens = train_test_split(\n",
    "        X_c2, y, test_size=val_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    val_pred_c2 = calibrated_model_c2.predict_proba(X_va_c2_ens)\n",
    "    print(f\"   OK shape: {val_pred_c2.shape}\")\n",
    "    print(f\"   Val LogLoss: {log_loss(y_va_c2_ens, val_pred_c2):.6f}\")\n",
    "    if val_pred_c1 is not None and len(y_va_c2_ens) != len(y_val_ensemble):\n",
    "        print(\"   Warning: validation set sizes do not match.\")\n",
    "else:\n",
    "    print(\"   Missing Candidate 2. Run the calibration cell.\")\n",
    "    val_pred_c2 = None\n",
    "\n",
    "# Candidate 3 (MLP + All Features)\n",
    "print(\"\\n3) Candidate 3 (MLP) validation predictions\")\n",
    "if 'X_c3' in locals() and 'calibrated_model_c3' in locals() and calibrated_model_c3 is not None:\n",
    "    X_tr_c3_ens, X_va_c3_ens, y_tr_c3_ens, y_va_c3_ens = train_test_split(\n",
    "        X_c3, y, test_size=val_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    scaler_c3_ens = StandardScaler()\n",
    "    X_tr_sc_c3_ens = scaler_c3_ens.fit_transform(X_tr_c3_ens)\n",
    "    X_va_sc_c3_ens = scaler_c3_ens.transform(X_va_c3_ens)\n",
    "    val_pred_c3 = calibrated_model_c3.predict_proba(X_va_sc_c3_ens)\n",
    "    print(f\"   OK shape: {val_pred_c3.shape}\")\n",
    "    print(f\"   Val LogLoss: {log_loss(y_va_c3_ens, val_pred_c3):.6f}\")\n",
    "else:\n",
    "    print(\"   Missing Candidate 3. Run the calibration cell.\")\n",
    "    val_pred_c3 = None\n",
    "\n",
    "# Individual model losses\n",
    "individual_val_losses = {}\n",
    "if val_pred_c1 is not None:\n",
    "    individual_val_losses['C1_DeBERTa'] = log_loss(y_val_ensemble, val_pred_c1)\n",
    "if val_pred_c2 is not None:\n",
    "    individual_val_losses['C2_XGBoost'] = log_loss(y_va_c2_ens, val_pred_c2)\n",
    "if val_pred_c3 is not None:\n",
    "    individual_val_losses['C3_MLP'] = log_loss(y_va_c3_ens, val_pred_c3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Individual Model Performance Summary\")\n",
    "for name, loss in individual_val_losses.items():\n",
    "    print(f\"   {name}: {loss:.6f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21fc6b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TESTING ENSEMBLE STRATEGIES\n",
      "================================================================================\n",
      "\n",
      "ERROR: Not all candidate models are available. Run all calibration cells first.\n"
     ]
    }
   ],
   "source": [
    "# === Section 2. Ensemble Strategy Search (simple, weighted, optimal, stacked, rank) ===\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING ENSEMBLE STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ensemble_results = {}\n",
    "\n",
    "if val_pred_c1 is not None and val_pred_c2 is not None and val_pred_c3 is not None:\n",
    "    print(\"\\nEnsuring a common validation set...\")\n",
    "    if len(val_pred_c1) == len(val_pred_c2) == len(val_pred_c3):\n",
    "        y_val_ref = y_val_ensemble\n",
    "        print(\"   All validation sizes match.\")\n",
    "    else:\n",
    "        min_size = min(len(val_pred_c1), len(val_pred_c2), len(val_pred_c3))\n",
    "        val_pred_c1 = val_pred_c1[:min_size]\n",
    "        val_pred_c2 = val_pred_c2[:min_size]\n",
    "        val_pred_c3 = val_pred_c3[:min_size]\n",
    "        y_val_ref = y_val_ensemble[:min_size]\n",
    "        print(f\"   Truncated to {min_size} samples.\")\n",
    "\n",
    "    val_preds_stacked = np.stack([val_pred_c1, val_pred_c2, val_pred_c3], axis=0)\n",
    "    num_classes = val_pred_c1.shape[1]\n",
    "\n",
    "    # Strategy 1: Simple average\n",
    "    print(\"\\nStrategy 1: Simple Average\")\n",
    "    ensemble_simple = np.mean(val_preds_stacked, axis=0)\n",
    "    loss_simple = log_loss(y_val_ref, ensemble_simple)\n",
    "    ensemble_results['Simple_Average'] = loss_simple\n",
    "    print(f\"   LogLoss: {loss_simple:.6f}\")\n",
    "\n",
    "    # Strategy 2: Weighted average by inverse log-loss\n",
    "    print(\"\\nStrategy 2: Weighted Average (inverse log loss)\")\n",
    "    losses = np.array([\n",
    "        log_loss(y_val_ref, val_pred_c1),\n",
    "        log_loss(y_val_ref, val_pred_c2),\n",
    "        log_loss(y_val_ref, val_pred_c3),\n",
    "    ])\n",
    "    inv_losses = 1.0 / losses\n",
    "    weights_perf = inv_losses / inv_losses.sum()\n",
    "    ensemble_weighted = (\n",
    "        weights_perf[0] * val_pred_c1 +\n",
    "        weights_perf[1] * val_pred_c2 +\n",
    "        weights_perf[2] * val_pred_c3\n",
    "    )\n",
    "    loss_weighted = log_loss(y_val_ref, ensemble_weighted)\n",
    "    ensemble_results['Weighted_Average'] = loss_weighted\n",
    "    print(f\"   Weights: {weights_perf.round(3).tolist()}\")\n",
    "    print(f\"   LogLoss: {loss_weighted:.6f}\")\n",
    "\n",
    "    # Strategy 3: Optimal weights via SLSQP\n",
    "    print(\"\\nStrategy 3: Optimal Weights (SLSQP)\")\n",
    "    def ensemble_loss(weights, preds, y_true):\n",
    "        w = np.array(weights, dtype=float)\n",
    "        w = w / w.sum()\n",
    "        ens = sum(w_i * p_i for w_i, p_i in zip(w, preds))\n",
    "        return log_loss(y_true, ens)\n",
    "\n",
    "    result = minimize(\n",
    "        lambda w: ensemble_loss(w, [val_pred_c1, val_pred_c2, val_pred_c3], y_val_ref),\n",
    "        x0=[1.0, 1.0, 1.0],\n",
    "        method='SLSQP',\n",
    "        bounds=[(0.01, 1.0)] * 3\n",
    "    )\n",
    "    optimal_weights = result.x / result.x.sum()\n",
    "    ensemble_optimal = (\n",
    "        optimal_weights[0] * val_pred_c1 +\n",
    "        optimal_weights[1] * val_pred_c2 +\n",
    "        optimal_weights[2] * val_pred_c3\n",
    "    )\n",
    "    loss_optimal = log_loss(y_val_ref, ensemble_optimal)\n",
    "    ensemble_results['Optimal_Weights'] = loss_optimal\n",
    "    print(f\"   Weights: {optimal_weights.round(3).tolist()}\")\n",
    "    print(f\"   LogLoss: {loss_optimal:.6f}\")\n",
    "\n",
    "    # Strategy 4: Stacked generalization\n",
    "    print(\"\\nStrategy 4: Stacked Generalization (Logistic Regression)\")\n",
    "    meta_features = np.hstack([val_pred_c1, val_pred_c2, val_pred_c3])\n",
    "    X_meta_tr, X_meta_va, y_meta_tr, y_meta_va = train_test_split(\n",
    "        meta_features, y_val_ref, test_size=0.3, random_state=random_state, stratify=y_val_ref\n",
    "    )\n",
    "    meta_learner = LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=random_state)\n",
    "    meta_learner.fit(X_meta_tr, y_meta_tr)\n",
    "    ensemble_stacked = meta_learner.predict_proba(X_meta_va)\n",
    "    loss_stacked = log_loss(y_meta_va, ensemble_stacked)\n",
    "    ensemble_results['Stacked_Generalization'] = loss_stacked\n",
    "    print(f\"   LogLoss: {loss_stacked:.6f}\")\n",
    "\n",
    "    # Strategy 5: Rank averaging (class-count agnostic)\n",
    "    print(\"\\nStrategy 5: Rank Averaging\")\n",
    "    def probs_to_ranks(probs):\n",
    "        ranks = np.zeros_like(probs, dtype=int)\n",
    "        for i in range(probs.shape[0]):\n",
    "            ranks[i] = np.argsort(np.argsort(-probs[i]))\n",
    "        return ranks\n",
    "\n",
    "    ranks_c1 = probs_to_ranks(val_pred_c1)\n",
    "    ranks_c2 = probs_to_ranks(val_pred_c2)\n",
    "    ranks_c3 = probs_to_ranks(val_pred_c3)\n",
    "    avg_ranks = (ranks_c1 + ranks_c2 + ranks_c3) / 3.0\n",
    "\n",
    "    ensemble_rank = np.zeros_like(val_pred_c1, dtype=float)\n",
    "    for i in range(avg_ranks.shape[0]):\n",
    "        scores = float(num_classes) - avg_ranks[i]  # lower rank -> higher score\n",
    "        scores = np.exp(scores)\n",
    "        ensemble_rank[i] = scores / scores.sum()\n",
    "    loss_rank = log_loss(y_val_ref, ensemble_rank)\n",
    "    ensemble_results['Rank_Averaging'] = loss_rank\n",
    "    print(f\"   LogLoss: {loss_rank:.6f}\")\n",
    "\n",
    "    # Summary and pick best\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ENSEMBLE STRATEGY COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    results_df = pd.DataFrame({\n",
    "        'Strategy': list(ensemble_results.keys()),\n",
    "        'Validation_LogLoss': list(ensemble_results.values())\n",
    "    }).sort_values('Validation_LogLoss')\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    best_strategy = results_df.iloc[0]['Strategy']\n",
    "    best_loss = results_df.iloc[0]['Validation_LogLoss']\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"BEST ENSEMBLE STRATEGY: {best_strategy}\")\n",
    "    print(f\"Validation LogLoss: {best_loss:.6f}\")\n",
    "\n",
    "    if individual_val_losses:\n",
    "        best_individual = min(individual_val_losses.values())\n",
    "        improvement = best_individual - best_loss\n",
    "        print(f\"\\nBest Individual: {best_individual:.6f}\")\n",
    "        print(f\"Improvement: {improvement:.6f} ({improvement / best_individual * 100:.2f}%)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Save decision\n",
    "    if best_strategy == 'Optimal_Weights':\n",
    "        final_ensemble_weights, final_ensemble_method = optimal_weights, 'optimal'\n",
    "    elif best_strategy == 'Weighted_Average':\n",
    "        final_ensemble_weights, final_ensemble_method = weights_perf, 'weighted'\n",
    "    elif best_strategy == 'Stacked_Generalization':\n",
    "        final_ensemble_weights, final_ensemble_method = None, 'stacked'\n",
    "    elif best_strategy == 'Rank_Averaging':\n",
    "        final_ensemble_weights, final_ensemble_method = None, 'rank'\n",
    "    else:\n",
    "        final_ensemble_weights, final_ensemble_method = np.array([1/3, 1/3, 1/3]), 'simple'\n",
    "else:\n",
    "    print(\"\\nERROR: Not all candidate models are available. Run all calibration cells first.\")\n",
    "    final_ensemble_method = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc3e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Section 3. Test-Time Ensembling and Final Summary ===\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING FINAL ENSEMBLE PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if final_ensemble_method is not None:\n",
    "    print(\"\\nLoading test predictions...\")\n",
    "    # C1\n",
    "    if 'test_probs_calibrated' in locals():\n",
    "        test_pred_c1 = test_probs_calibrated\n",
    "        print(f\"   C1 shape: {test_pred_c1.shape}\")\n",
    "    else:\n",
    "        print(\"   C1 calibrated not found. Using uncalibrated if present.\")\n",
    "        test_pred_c1 = test_probs if 'test_probs' in locals() else None\n",
    "    # C2\n",
    "    if 'pred_c2_calibrated' in locals():\n",
    "        test_pred_c2 = pred_c2_calibrated\n",
    "        print(f\"   C2 shape: {test_pred_c2.shape}\")\n",
    "    else:\n",
    "        print(\"   C2 calibrated not found. Generating if possible.\")\n",
    "        if 'calibrated_final_c2' in locals() and 'X_test_c2' in locals():\n",
    "            test_pred_c2 = calibrated_final_c2.predict_proba(X_test_c2)\n",
    "            print(f\"   Generated C2: {test_pred_c2.shape}\")\n",
    "        else:\n",
    "            test_pred_c2 = None\n",
    "    # C3\n",
    "    if 'pred_c3_calibrated' in locals():\n",
    "        test_pred_c3 = pred_c3_calibrated\n",
    "        print(f\"   C3 shape: {test_pred_c3.shape}\")\n",
    "    else:\n",
    "        print(\"   C3 calibrated not found. Generating if possible.\")\n",
    "        if 'calibrated_final_c3' in locals() and 'X_test_c3' in locals():\n",
    "            scaler_temp = StandardScaler()\n",
    "            scaler_temp.fit(X_c3)\n",
    "            X_test_scaled = scaler_temp.transform(X_test_c3)\n",
    "            test_pred_c3 = calibrated_final_c3.predict_proba(X_test_scaled)\n",
    "            print(f\"   Generated C3: {test_pred_c3.shape}\")\n",
    "        else:\n",
    "            test_pred_c3 = None\n",
    "\n",
    "    if test_pred_c1 is not None and test_pred_c2 is not None and test_pred_c3 is not None:\n",
    "        print(f\"\\nUsing ensemble method: {final_ensemble_method.upper()}\")\n",
    "        if final_ensemble_method == 'simple':\n",
    "            final_test_pred = (test_pred_c1 + test_pred_c2 + test_pred_c3) / 3.0\n",
    "        elif final_ensemble_method in ['optimal', 'weighted']:\n",
    "            final_test_pred = (\n",
    "                final_ensemble_weights[0] * test_pred_c1 +\n",
    "                final_ensemble_weights[1] * test_pred_c2 +\n",
    "                final_ensemble_weights[2] * test_pred_c3\n",
    "            )\n",
    "        elif final_ensemble_method == 'stacked':\n",
    "            test_meta_features = np.hstack([test_pred_c1, test_pred_c2, test_pred_c3])\n",
    "            final_test_pred = meta_learner.predict_proba(test_meta_features)\n",
    "        elif final_ensemble_method == 'rank':\n",
    "            def probs_to_ranks_test(probs):\n",
    "                ranks = np.zeros_like(probs, dtype=int)\n",
    "                for i in range(probs.shape[0]):\n",
    "                    ranks[i] = np.argsort(np.argsort(-probs[i]))\n",
    "                return ranks\n",
    "            ranks_test_c1 = probs_to_ranks_test(test_pred_c1)\n",
    "            ranks_test_c2 = probs_to_ranks_test(test_pred_c2)\n",
    "            ranks_test_c3 = probs_to_ranks_test(test_pred_c3)\n",
    "            avg_ranks_test = (ranks_test_c1 + ranks_test_c2 + ranks_test_c3) / 3.0\n",
    "            num_classes_test = test_pred_c1.shape[1]\n",
    "            final_test_pred = np.zeros_like(test_pred_c1, dtype=float)\n",
    "            for i in range(avg_ranks_test.shape[0]):\n",
    "                scores = float(num_classes_test) - avg_ranks_test[i]\n",
    "                scores = np.exp(scores)\n",
    "                final_test_pred[i] = scores / scores.sum()\n",
    "\n",
    "        # Safety normalization\n",
    "        row_sums = final_test_pred.sum(axis=1, keepdims=True)\n",
    "        final_test_pred = final_test_pred / np.clip(row_sums, 1e-15, None)\n",
    "\n",
    "        print(f\"\\nFinal predictions shape: {final_test_pred.shape}\")\n",
    "        print(f\"Probability sum check (first 5): {final_test_pred[:5].sum(axis=1)}\")\n",
    "\n",
    "        final_filename = f\"submission_FINAL_ENSEMBLE_{final_ensemble_method.upper()}.csv\"\n",
    "        create_and_save_submission(\n",
    "            predictions=final_test_pred,\n",
    "            filename=final_filename,\n",
    "            test_df=test,\n",
    "            sample_df=sample\n",
    "        )\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FINAL ENSEMBLE SUBMISSION CREATED\")\n",
    "        print(f\"File: {final_filename}\")\n",
    "        print(f\"Method: {final_ensemble_method.upper()}\")\n",
    "        print(f\"Expected Validation LogLoss: ~{best_loss:.6f}\")\n",
    "        print(\"=\"*80)\n",
    "    else:\n",
    "        print(\"\\nERROR: Missing test predictions for one or more candidates.\")\n",
    "else:\n",
    "    print(\"\\nERROR: Ensemble method not determined. Run Section 2 first.\")\n",
    "\n",
    "# Final summary of generated submissions and optional performance echo\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL SUBMISSION FILES GENERATED\")\n",
    "print(\"=\"*80)\n",
    "submission_files = sorted(glob.glob(\"submission_*.csv\"))\n",
    "if submission_files:\n",
    "    print(f\"\\nTotal submissions created: {len(submission_files)}\\n\")\n",
    "    buckets = {\n",
    "        \"Step 1 (Baseline)\": [f for f in submission_files if 'step1' in f],\n",
    "        \"Step 2 (Embeddings)\": [f for f in submission_files if 'step2' in f],\n",
    "        \"Candidate 1 (DeBERTa + LoRA)\": [f for f in submission_files if 'candidate1' in f],\n",
    "        \"Candidate 2 (XGBoost/LGBM)\": [f for f in submission_files if 'candidate2' in f],\n",
    "        \"Candidate 3 (MLP + All Features)\": [f for f in submission_files if 'candidate3' in f],\n",
    "        \"FINAL ENSEMBLE\": [f for f in submission_files if 'ENSEMBLE' in f],\n",
    "    }\n",
    "    for k, files in buckets.items():\n",
    "        if files:\n",
    "            print(k)\n",
    "            for f in files:\n",
    "                sz = os.path.getsize(f) / (1024 * 1024)\n",
    "                cal = \"CALIBRATED\" if \"CALIBRATED\" in f else \"\"\n",
    "                print(f\"   - {f:60s} ({sz:.2f} MB) {cal}\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"\\nNo submission files found. Generate predictions first.\")\n",
    "\n",
    "if 'ensemble_results' in locals() and ensemble_results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VALIDATION PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    if 'individual_val_losses' in locals():\n",
    "        print(\"\\nIndividual Models (Calibrated):\")\n",
    "        for name, loss in sorted(individual_val_losses.items(), key=lambda x: x[1]):\n",
    "            print(f\"   {name:25s}: {loss:.6f}\")\n",
    "    print(\"\\nEnsemble Methods:\")\n",
    "    for name, loss in sorted(ensemble_results.items(), key=lambda x: x[1]):\n",
    "        print(f\"   {name:25s}: {loss:.6f}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jun_cls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
