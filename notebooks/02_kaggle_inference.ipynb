{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ef8c36",
   "metadata": {
    "papermill": {
     "duration": 0.002291,
     "end_time": "2025-11-06T10:49:12.905267",
     "exception": false,
     "start_time": "2025-11-06T10:49:12.902976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Team7 Assignment 2: Kaggle Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e233b5",
   "metadata": {
    "papermill": {
     "duration": 0.001577,
     "end_time": "2025-11-06T10:49:12.908987",
     "exception": false,
     "start_time": "2025-11-06T10:49:12.907410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setting and Dataset Load (C2-Only Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b14d7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T10:49:12.913208Z",
     "iopub.status.busy": "2025-11-06T10:49:12.913014Z",
     "iopub.status.idle": "2025-11-06T10:49:43.153186Z",
     "shell.execute_reply": "2025-11-06T10:49:43.152403Z"
    },
    "papermill": {
     "duration": 30.245274,
     "end_time": "2025-11-06T10:49:43.155976",
     "exception": false,
     "start_time": "2025-11-06T10:49:12.910702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 10:49:30.201743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762426170.402188      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762426170.454973      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: /kaggle/input/llm-classification-finetuning (3, 4)\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "import torch\n",
    "import joblib, time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.special import softmax\n",
    "\n",
    "# =========================================================================\n",
    "# Kaggle Dataset 경로 설정\n",
    "# =========================================================================\n",
    "KAGGLE_MODEL_DIR = \"/kaggle/input/models/models\"\n",
    "KAGGLE_DATA_DIR = \"/kaggle/input/llm-classification-finetuning\"\n",
    "BASE_DIR = KAGGLE_MODEL_DIR\n",
    "\n",
    "# Data Load (Inference에는 test와 sample만 필요)\n",
    "test  = pd.read_csv(f\"{KAGGLE_DATA_DIR}/test.csv\")\n",
    "sample = pd.read_csv(f\"{KAGGLE_DATA_DIR}/sample_submission.csv\")\n",
    "\n",
    "print(\"DATA:\", KAGGLE_DATA_DIR, test.shape)\n",
    "\n",
    "random_state = 20010815\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176360b7",
   "metadata": {
    "papermill": {
     "duration": 0.001746,
     "end_time": "2025-11-06T10:49:43.159616",
     "exception": false,
     "start_time": "2025-11-06T10:49:43.157870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Global Functions (C2-Required Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0de15d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T10:49:43.164329Z",
     "iopub.status.busy": "2025-11-06T10:49:43.163842Z",
     "iopub.status.idle": "2025-11-06T10:49:43.179654Z",
     "shell.execute_reply": "2025-11-06T10:49:43.178939Z"
    },
    "papermill": {
     "duration": 0.019288,
     "end_time": "2025-11-06T10:49:43.180673",
     "exception": false,
     "start_time": "2025-11-06T10:49:43.161385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All C2-related functions loaded.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def load_model(candidates, idx=0, device=\"cpu\"):\n",
    "    last_err = None\n",
    "    path = candidates[idx]\n",
    "    try:\n",
    "        print(\"try:\", path)\n",
    "        model = SentenceTransformer(path, device=device)\n",
    "        print(\"loaded model from:\", path)\n",
    "        return model, path\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "    raise RuntimeError(\"Failed to load model. \" + str(last_err))\n",
    "\n",
    "def build_feat(P, A, B):\n",
    "    AB_diff = A - B\n",
    "    AB_adiff = np.abs(AB_diff)\n",
    "    AB_mul = A * B\n",
    "    PA_mul = P * A\n",
    "    PB_mul = P * B\n",
    "    return np.hstack([P, A, B, AB_diff, AB_adiff, AB_mul, PA_mul, PB_mul])\n",
    "\n",
    "def l2norm(a, eps=1e-12):\n",
    "    n = np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    n = np.clip(n, eps, None)\n",
    "    return a / n\n",
    "\n",
    "def encode_texts(model, texts, batch_size=256):\n",
    "    vecs = []\n",
    "    total_texts = len(texts)\n",
    "    total_batches = (total_texts + batch_size - 1) // batch_size\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        start_time = time.time()\n",
    "        batch = texts[i:i+batch_size].tolist() if isinstance(texts, pd.Series) else texts[i:i+batch_size]\n",
    "        v = model.encode(batch, batch_size=len(batch), convert_to_numpy=True, normalize_embeddings=False, show_progress_bar=False)\n",
    "        vecs.append(v)\n",
    "\n",
    "        batch_num = (i // batch_size) + 1\n",
    "        print(f\"{batch_num}/{total_batches} | time: {time.time() - start_time:.2f}s\", end='\\r', flush=True)\n",
    "    V = np.vstack(vecs)\n",
    "    return l2norm(V)\n",
    "\n",
    "def create_and_save_submission(predictions, filename, test_df, sample_df):\n",
    "    print(f\"Creating submission file: {filename}...\")\n",
    "    sub_df = pd.DataFrame({\n",
    "        \"id\": test_df[\"id\"],\n",
    "        \"winner_model_a\": predictions[:, 0],\n",
    "        \"winner_model_b\": predictions[:, 1],\n",
    "        \"winner_tie\":     predictions[:, 2],\n",
    "    })\n",
    "    probs = sub_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n",
    "    row_sums = probs.sum(axis=1, keepdims=True)\n",
    "    probs = probs / np.clip(row_sums, 1e-15, None)\n",
    "    sub_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]] = probs\n",
    "    try:\n",
    "        sub_df = sub_df[sample_df.columns]\n",
    "    except KeyError as e:\n",
    "        print(f\"Warning: Columns in sample_df not found. Error: {e}\")\n",
    "    sub_df.to_csv(filename, index=False)\n",
    "    try:\n",
    "        chk = pd.read_csv(filename)\n",
    "        assert list(chk.columns) == list(sample_df.columns)\n",
    "        assert not chk.isna().any().any()\n",
    "        prob_cols = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
    "        assert np.allclose(chk[prob_cols].sum(1).values, 1.0)\n",
    "        print(f\"Successfully saved and verified: {filename} (Shape: {sub_df.shape})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Submission file verification failed! {e}\")\n",
    "    return sub_df\n",
    "\n",
    "print(\"All C2-related functions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55473c9",
   "metadata": {
    "papermill": {
     "duration": 0.001685,
     "end_time": "2025-11-06T10:49:43.184171",
     "exception": false,
     "start_time": "2025-11-06T10:49:43.182486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step 1. Generate C2 (XGBoost) Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1c968a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T10:49:43.188852Z",
     "iopub.status.busy": "2025-11-06T10:49:43.188368Z",
     "iopub.status.idle": "2025-11-06T10:49:53.465559Z",
     "shell.execute_reply": "2025-11-06T10:49:53.464645Z"
    },
    "papermill": {
     "duration": 10.280909,
     "end_time": "2025-11-06T10:49:53.466921",
     "exception": false,
     "start_time": "2025-11-06T10:49:43.186012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Candidate 2: PLM + XGBoost ---\n",
      "try: /kaggle/input/models/models/e5-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model from: /kaggle/input/models/models/e5-base-v2\n",
      "C2 test features (X_test_c2) generated.\n",
      "C2 test predictions successfully generated and calibrated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [10:49:53] WARNING: /workspace/src/common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator IsotonicRegression from version 1.7.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CalibratedClassifierCV from version 1.7.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### C2: PLM + XGBoost (Calibrated) ###\n",
    "MODEL_NAME_C2 = \"e5-base-v2\"\n",
    "C2_MODEL_PATH = f\"{BASE_DIR}/{MODEL_NAME_C2}\"\n",
    "GBM_CHOICE = \"XGBOOST\"\n",
    "C2_CALIBRATED_MODEL_PATH = f\"{BASE_DIR}/candidate_2_{GBM_CHOICE}_{MODEL_NAME_C2}_CALIBRATED.pkl\"\n",
    "\n",
    "print(\"--- Candidate 2: PLM + XGBoost ---\")\n",
    "final_test_pred = None\n",
    "\n",
    "try:\n",
    "    # 1. Load Embedding Model and Generate Test Features (X_test_c2)\n",
    "    sbert_model, _ = load_model([C2_MODEL_PATH], idx=0, device=device)\n",
    "    prompt_emb_te = encode_texts(sbert_model, test[\"prompt\"])\n",
    "    a_emb_te = encode_texts(sbert_model, test[\"response_a\"])\n",
    "    b_emb_te = encode_texts(sbert_model, test[\"response_b\"])\n",
    "    X_test_c2 = build_feat(prompt_emb_te, a_emb_te, b_emb_te)\n",
    "    del sbert_model, prompt_emb_te, a_emb_te, b_emb_te\n",
    "    print(\"C2 test features (X_test_c2) generated.\")\n",
    "    \n",
    "    # 2. Load Final Calibrated Model and Predict\n",
    "    calibrated_final_c2 = joblib.load(C2_CALIBRATED_MODEL_PATH)\n",
    "    final_test_pred = calibrated_final_c2.predict_proba(X_test_c2)\n",
    "    print(\"C2 test predictions successfully generated and calibrated.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR in C2 processing: {e}\")\n",
    "    final_test_pred = np.zeros((len(test), 3)) # Placeholder\n",
    "    \n",
    "if device == 'cuda': torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681c8c2",
   "metadata": {
    "papermill": {
     "duration": 0.002162,
     "end_time": "2025-11-06T10:49:53.472063",
     "exception": false,
     "start_time": "2025-11-06T10:49:53.469901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step 2. Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fbc066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T10:49:53.477748Z",
     "iopub.status.busy": "2025-11-06T10:49:53.477158Z",
     "iopub.status.idle": "2025-11-06T10:49:53.498084Z",
     "shell.execute_reply": "2025-11-06T10:49:53.497281Z"
    },
    "papermill": {
     "duration": 0.024842,
     "end_time": "2025-11-06T10:49:53.499128",
     "exception": false,
     "start_time": "2025-11-06T10:49:53.474286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING FINAL SUBMISSION (C2-ONLY)\n",
      "================================================================================\n",
      "\n",
      "Final predictions shape: (3, 3)\n",
      "Probability sum check (first 3): [1. 1. 1.]\n",
      "Creating submission file: submission.csv...\n",
      "Successfully saved and verified: submission.csv (Shape: (3, 4))\n",
      "\n",
      "================================================================================\n",
      "FINAL SUBMISSION CREATED\n",
      "File: submission.csv\n",
      "Method: C2 (XGBoost) ONLY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING FINAL SUBMISSION (C2-ONLY)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# final_test_pred 변수가 C2 예측 단계에서 생성되었는지 확인\n",
    "if 'final_test_pred' in locals() and final_test_pred is not None and final_test_pred.shape[0] == len(test):\n",
    "    print(f\"\\nFinal predictions shape: {final_test_pred.shape}\")\n",
    "    print(f\"Probability sum check (first 3): {final_test_pred[:3].sum(axis=1)}\")\n",
    "\n",
    "    final_filename = f\"submission.csv\"\n",
    "    create_and_save_submission(\n",
    "        predictions=final_test_pred,\n",
    "        filename=final_filename,\n",
    "        test_df=test,\n",
    "        sample_df=sample\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL SUBMISSION CREATED\")\n",
    "    print(f\"File: {final_filename}\")\n",
    "    print(\"Method: C2 (XGBoost) ONLY\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\nERROR: C2 predictions not found or shape mismatch.\")\n",
    "    print(\"Submission file not created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "isSourceIdPinned": false,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "datasetId": 8665124,
     "sourceId": 13632921,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.921978,
   "end_time": "2025-11-06T10:49:56.357997",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-06T10:49:09.436019",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
